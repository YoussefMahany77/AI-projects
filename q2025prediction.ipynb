{
 "cells": [
   {
    "cell_type": "markdown",
    "source": [
     "# Sales Forecasting for Q2 2025\n",
     "\n",
     "## Objective\n",
     "This notebook aims to predict daily sales for the second quarter of 2025 (April 1, 2025, to June 30, 2025). It utilizes a hybrid forecasting model combining Gradient Boosting and LSTM to capture both trend/seasonality and non-linear patterns in the sales data.\n",
     "\n",
     "## Notebook Structure\n",
     "The notebook is organized into the following main sections:\n",
     "\n",
     "1.  **Setup & Data Loading:** Installation of required libraries and loading the `newcleanedsales.xlsx` dataset.\n",
     "2.  **Initial Data Exploration:** Basic overview of the data, including its structure, data types, missing values, and descriptive statistics.\n",
     "3.  **Data Preprocessing:** Steps taken to clean and prepare the data for modeling, such as:\n",
     "    *   Renaming columns for clarity.\n",
     "    *   Converting data types (e.g., 'Date' to datetime, 'Sales' to numeric).\n",
     "    *   Handling missing values.\n",
     "    *   Aggregating sales data to a daily level.\n",
     "    *   Feature engineering to create time-based features (Month, Year, DayOfWeek, etc.).\n",
     "4.  **Model Definition (`EnhancedHybridModel`):** Definition of the custom hybrid model class that combines a Gradient Boosting Regressor (for trend and seasonality) and an LSTM network (for residuals).\n",
     "5.  **Model Training:** \n",
     "    *   Splitting the daily sales data into training and validation sets.\n",
     "    *   Training the `EnhancedHybridModel` on the training data.\n",
     "6.  **Model Evaluation:** \n",
     "    *   Evaluating the model's performance on the validation set using metrics like MAE, RMSE, and MAPE.\n",
     "    *   Visualizing actual vs. predicted sales on the validation set.\n",
     "7.  **Q2 2025 Sales Prediction:**\n",
     "    *   Forecasting daily sales for Q2 2025.\n",
     "    *   Displaying the daily predictions and the total predicted sales for the quarter.\n",
     "    *   Visualizing the Q2 2025 forecast in the context of historical data.\n",
     "\n",
     "**Note on Data:** The sales data is expected to be in an Excel file named `newcleanedsales.xlsx` in the same directory as the notebook. The relevant columns for the initial analysis are 'التاريخ' (Date) and 'إجمالى البيع' (Total Sales)."
    ]
   },
   {
    "cell_type": "markdown",
    "source": [
     "## 0. Setup and Library Installation"
    ]
   },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 435.7 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.8 MB 871.5 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.8 MB 853.3 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.8 MB 1.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.4/1.8 MB 1.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "# 1. Install Required Libraries\n",
    "!pip install --upgrade pip --quiet\n",
    "!pip install pandas scikit-learn matplotlib ipywidgets tensorflow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load and Initially Explore the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section loads the sales data from the `newcleanedsales.xlsx` file and performs an initial exploration to understand its structure, content, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'newcleanedsales.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print DataFrame information\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Observations:\n",
    "\n",
    "**Relevant Columns for Forecasting:**\n",
    "\n",
    "*   `التاريخ` (Date): Crucial for time series analysis.\n",
    "*   `إجمالى البيع` (Sales): The target variable for prediction.\n",
    "*   Other columns like `اسم الصنف` (ItemName), `الموقع` (Location), `العميل` (Customer) could be used for more granular forecasts or as features if aggregated properly.\n",
    "\n",
    "**Missing Data:**\n",
    "\n",
    "*   The `df.info()` output will show non-null counts. We need to check if any key columns (`التاريخ`, `إجمالى البيع`) have missing values.\n",
    "*   The original notebook already contains steps to handle missing values in 'Date' and 'Sales' by dropping rows where these are NaN. This seems like a reasonable first approach.\n",
    "\n",
    "**Potential Outliers & Data Types:**\n",
    "\n",
    "*   `إجمالى البيع` (Sales), `سعر القائمة` (ListPrice), `إجمالى التكاليف` (TotalCosts), `تكلفة الوحدة` (UnitCost), `الكمية` (Quantity) are numerical. `describe()` will give insights into their distributions (mean, std, min, max).\n",
    "*   Large differences between mean and median, or very high std dev, might indicate outliers in these numerical columns.\n",
    "*   The `التاريخ` column is initially an object type and is correctly converted to datetime in the subsequent cells of the original notebook.\n",
    "*   Categorical columns like `اسم الصنف`, `الموقع`, `العميل` will have their unique counts and top/freq shown in `describe(include='all')`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "This section covers the necessary steps to clean and transform the raw sales data into a format suitable for time series forecasting. This includes renaming columns, converting data types, handling missing values, aggregating data to a daily frequency, and engineering relevant time-based features."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Column Renaming and Initial Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    'إجمالى البيع': 'Sales',\n",
    "    'التاريخ': 'Date',\n",
    "    'سعر القائمة': 'ListPrice',\n",
    "    'إجمالى التكاليف': 'TotalCosts',\n",
    "    'تكلفة الوحدة': 'UnitCost',\n",
    "    'الكمية': 'Quantity',\n",
    "    'اسم الصنف': 'ItemName',\n",
    "    'الموقع': 'Location',\n",
    "    'العميل': 'Customer'\n",
    "}, inplace=True)\n",
    "print(\"DataFrame head after renaming columns:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>إجمالى البيع</th>\n",
       "      <th>سعر القائمة</th>\n",
       "      <th>إجمالى التكاليف</th>\n",
       "      <th>تكلفة الوحدة</th>\n",
       "      <th>الكمية</th>\n",
       "      <th>اسم الصنف</th>\n",
       "      <th>الموقع</th>\n",
       "      <th>العميل</th>\n",
       "      <th>التاريخ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>الرحاب</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>المعادى 2</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>31.3992</td>\n",
       "      <td>15.6996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>مدينة نصر 4</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>القاهرة الجديدة</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>شروق</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108111</th>\n",
       "      <td>37.3125</td>\n",
       "      <td>37.3125</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>بطاطس (فريش روتس) (2 كجم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108112</th>\n",
       "      <td>16.3125</td>\n",
       "      <td>16.3125</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108113</th>\n",
       "      <td>27.5600</td>\n",
       "      <td>27.5600</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108114</th>\n",
       "      <td>20.2100</td>\n",
       "      <td>20.2100</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>طماطم (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>46.4625</td>\n",
       "      <td>46.4625</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>فلفل رومى أخضر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108116 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        إجمالى البيع  سعر القائمة  إجمالى التكاليف  تكلفة الوحدة  الكمية  \\\n",
       "0            97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "1            97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "2            97.5000      48.7500          31.3992       15.6996     2.0   \n",
       "3            97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "4            97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "...              ...          ...              ...           ...     ...   \n",
       "108111       37.3125      37.3125          22.0160       22.0160     1.0   \n",
       "108112       16.3125      16.3125           6.6352        6.6352     1.0   \n",
       "108113       27.5600      27.5600          12.5915       12.5915     1.0   \n",
       "108114       20.2100      20.2100          13.3352       13.3352     1.0   \n",
       "108115       46.4625      46.4625          28.7080       28.7080     1.0   \n",
       "\n",
       "                                     اسم الصنف           الموقع      العميل  \\\n",
       "0                              كرنب احمر (خ.ب)           الرحاب  Bread fast   \n",
       "1                              كرنب احمر (خ.ب)        المعادى 2  Bread fast   \n",
       "2                              كرنب احمر (خ.ب)      مدينة نصر 4  Bread fast   \n",
       "3                              كرنب احمر (خ.ب)  القاهرة الجديدة  Bread fast   \n",
       "4                              كرنب احمر (خ.ب)             شروق  Bread fast   \n",
       "...                                        ...              ...         ...   \n",
       "108111               بطاطس (فريش روتس) (2 كجم)           اكتوبر    رابت مصر   \n",
       "108112             جزر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "108113            جزر (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108114          طماطم (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108115  فلفل رومى أخضر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "\n",
       "          التاريخ  \n",
       "0      2025-01-01  \n",
       "1      2025-01-01  \n",
       "2      2025-01-02  \n",
       "3      2025-01-06  \n",
       "4      2025-01-06  \n",
       "...           ...  \n",
       "108111 2025-03-29  \n",
       "108112 2025-03-29  \n",
       "108113 2025-03-29  \n",
       "108114 2025-03-29  \n",
       "108115 2025-03-29  \n",
       "\n",
       "[108116 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>إجمالى البيع</th>\n",
       "      <th>سعر القائمة</th>\n",
       "      <th>إجمالى التكاليف</th>\n",
       "      <th>تكلفة الوحدة</th>\n",
       "      <th>الكمية</th>\n",
       "      <th>اسم الصنف</th>\n",
       "      <th>الموقع</th>\n",
       "      <th>العميل</th>\n",
       "      <th>التاريخ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>الرحاب</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>المعادى 2</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>31.3992</td>\n",
       "      <td>15.6996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>مدينة نصر 4</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>القاهرة الجديدة</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>شروق</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108111</th>\n",
       "      <td>37.3125</td>\n",
       "      <td>37.3125</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>بطاطس (فريش روتس) (2 كجم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108112</th>\n",
       "      <td>16.3125</td>\n",
       "      <td>16.3125</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108113</th>\n",
       "      <td>27.5600</td>\n",
       "      <td>27.5600</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108114</th>\n",
       "      <td>20.2100</td>\n",
       "      <td>20.2100</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>طماطم (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>46.4625</td>\n",
       "      <td>46.4625</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>فلفل رومى أخضر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108116 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        إجمالى البيع  سعر القائمة  إجمالى التكاليف  تكلفة الوحدة  الكمية  \\\n",
       "0            97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "1            97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "2            97.5000      48.7500          31.3992       15.6996     2.0   \n",
       "3            97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "4            97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "...              ...          ...              ...           ...     ...   \n",
       "108111       37.3125      37.3125          22.0160       22.0160     1.0   \n",
       "108112       16.3125      16.3125           6.6352        6.6352     1.0   \n",
       "108113       27.5600      27.5600          12.5915       12.5915     1.0   \n",
       "108114       20.2100      20.2100          13.3352       13.3352     1.0   \n",
       "108115       46.4625      46.4625          28.7080       28.7080     1.0   \n",
       "\n",
       "                                     اسم الصنف           الموقع      العميل  \\\n",
       "0                              كرنب احمر (خ.ب)           الرحاب  Bread fast   \n",
       "1                              كرنب احمر (خ.ب)        المعادى 2  Bread fast   \n",
       "2                              كرنب احمر (خ.ب)      مدينة نصر 4  Bread fast   \n",
       "3                              كرنب احمر (خ.ب)  القاهرة الجديدة  Bread fast   \n",
       "4                              كرنب احمر (خ.ب)             شروق  Bread fast   \n",
       "...                                        ...              ...         ...   \n",
       "108111               بطاطس (فريش روتس) (2 كجم)           اكتوبر    رابت مصر   \n",
       "108112             جزر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "108113            جزر (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108114          طماطم (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108115  فلفل رومى أخضر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "\n",
       "          التاريخ  \n",
       "0      2025-01-01  \n",
       "1      2025-01-01  \n",
       "2      2025-01-02  \n",
       "3      2025-01-06  \n",
       "4      2025-01-06  \n",
       "...           ...  \n",
       "108111 2025-03-29  \n",
       "108112 2025-03-29  \n",
       "108113 2025-03-29  \n",
       "108114 2025-03-29  \n",
       "108115 2025-03-29  \n",
       "\n",
       "[108116 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Type Conversion\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "\n",
    "# Handle Missing Values\n",
    "df.dropna(subset=['Date', 'Sales'], inplace=True)\n",
    "\n",
    "print(\"DataFrame head after type conversion and NA drop:\")\n",
    "display(df.head())\n",
    "print(\"\\nDataFrame info after type conversion and NA drop:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>سعر القائمة</th>\n",
       "      <th>إجمالى التكاليف</th>\n",
       "      <th>تكلفة الوحدة</th>\n",
       "      <th>الكمية</th>\n",
       "      <th>اسم الصنف</th>\n",
       "      <th>الموقع</th>\n",
       "      <th>العميل</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>الرحاب</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>34.2512</td>\n",
       "      <td>17.1256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>المعادى 2</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>31.3992</td>\n",
       "      <td>15.6996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>مدينة نصر 4</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>القاهرة الجديدة</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.5000</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>30.7266</td>\n",
       "      <td>15.3633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>كرنب احمر (خ.ب)</td>\n",
       "      <td>شروق</td>\n",
       "      <td>Bread fast</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108111</th>\n",
       "      <td>37.3125</td>\n",
       "      <td>37.3125</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>22.0160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>بطاطس (فريش روتس) (2 كجم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108112</th>\n",
       "      <td>16.3125</td>\n",
       "      <td>16.3125</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>6.6352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108113</th>\n",
       "      <td>27.5600</td>\n",
       "      <td>27.5600</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>12.5915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>جزر (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108114</th>\n",
       "      <td>20.2100</td>\n",
       "      <td>20.2100</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>13.3352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>طماطم (فريش روتس) (1 كجم)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>46.4625</td>\n",
       "      <td>46.4625</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>28.7080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>فلفل رومى أخضر (500جم)(فريش روتس)(فوم)</td>\n",
       "      <td>اكتوبر</td>\n",
       "      <td>رابت مصر</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107665 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sales  سعر القائمة  إجمالى التكاليف  تكلفة الوحدة  الكمية  \\\n",
       "0       97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "1       97.5000      48.7500          34.2512       17.1256     2.0   \n",
       "2       97.5000      48.7500          31.3992       15.6996     2.0   \n",
       "3       97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "4       97.5000      48.7500          30.7266       15.3633     2.0   \n",
       "...         ...          ...              ...           ...     ...   \n",
       "108111  37.3125      37.3125          22.0160       22.0160     1.0   \n",
       "108112  16.3125      16.3125           6.6352        6.6352     1.0   \n",
       "108113  27.5600      27.5600          12.5915       12.5915     1.0   \n",
       "108114  20.2100      20.2100          13.3352       13.3352     1.0   \n",
       "108115  46.4625      46.4625          28.7080       28.7080     1.0   \n",
       "\n",
       "                                     اسم الصنف           الموقع      العميل  \\\n",
       "0                              كرنب احمر (خ.ب)           الرحاب  Bread fast   \n",
       "1                              كرنب احمر (خ.ب)        المعادى 2  Bread fast   \n",
       "2                              كرنب احمر (خ.ب)      مدينة نصر 4  Bread fast   \n",
       "3                              كرنب احمر (خ.ب)  القاهرة الجديدة  Bread fast   \n",
       "4                              كرنب احمر (خ.ب)             شروق  Bread fast   \n",
       "...                                        ...              ...         ...   \n",
       "108111               بطاطس (فريش روتس) (2 كجم)           اكتوبر    رابت مصر   \n",
       "108112             جزر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "108113            جزر (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108114          طماطم (فريش روتس) (1 كجم)(فوم)           اكتوبر    رابت مصر   \n",
       "108115  فلفل رومى أخضر (500جم)(فريش روتس)(فوم)           اكتوبر    رابت مصر   \n",
       "\n",
       "             Date  \n",
       "0      2025-01-01  \n",
       "1      2025-01-01  \n",
       "2      2025-01-02  \n",
       "3      2025-01-06  \n",
       "4      2025-01-06  \n",
       "...           ...  \n",
       "108111 2025-03-29  \n",
       "108112 2025-03-29  \n",
       "108113 2025-03-29  \n",
       "108114 2025-03-29  \n",
       "108115 2025-03-29  \n",
       "\n",
       "[107665 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate Sales Data\n",
    "df_daily_sales = df.groupby('Date')['Sales'].sum().reset_index()\n",
    "df_daily_sales.sort_values('Date', inplace=True)\n",
    "\n",
    "print(\"Daily aggregated sales head (df_daily_sales with 'Date' as a column before setting index):\")\n",
    "display(df_daily_sales.head())\n",
    "print(\"\\nDaily aggregated sales info (df_daily_sales before setting index):\")\n",
    "df_daily_sales.info()\n",
    "\n",
    "# Set 'Date' column as index\n",
    "df_daily_sales.set_index('Date', inplace=True)\n",
    "print(\"\\nDaily aggregated sales head (df_daily_sales with 'Date' as index):\")\n",
    "display(df_daily_sales.head())\n",
    "print(\"\\nDaily aggregated sales info (df_daily_sales with 'Date' as index):\")\n",
    "df_daily_sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregation to Daily Sales and Indexing by Date\n",
    "\n",
    "The sales data is aggregated to a daily level to simplify the time series and make it suitable for the forecasting model. The 'Date' column is then set as the DataFrame's index, which is a standard practice for time series analysis in pandas and facilitates time-based operations and plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Justification for Missing Value Handling (Post-Aggregation Focus):\n",
    "\n",
    "The original notebook already implements a strategy to handle missing values for the critical 'Date' and 'Sales' columns:\n",
    "```python\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "df.dropna(subset=['Date', 'Sales'], inplace=True)\n",
    "```\n",
    "This approach is justified because:\n",
    "1.  **Criticality of Columns:** Accurate date and sales figures are fundamental for time series forecasting. Rows with missing values in these columns provide little to no value for training a sales forecasting model.\n",
    "2.  **Coercion and Removal:** Converting 'Date' to datetime with `errors='coerce'` turns unparseable dates into `NaT` (Not a Time). Similarly, `pd.to_numeric` with `errors='coerce'` turns non-numeric sales data into `NaN`. Subsequently, `dropna` removes these problematic rows.\n",
    "3.  **Impact of Removal:** Assuming the number of rows dropped is small relative to the dataset size, this method is a straightforward and effective way to ensure data quality for these key fields. If a large number of rows were to be dropped, further investigation into the data source or alternative imputation methods (like interpolation for sales, if appropriate and if dates were present) might be needed. However, for building an initial model, removal is a common first step.\n",
    "\n",
    "For other columns, missing value strategies would depend on their nature and importance as potential features. Since the current model primarily uses aggregated daily sales (from `df_daily_sales`), the handling of missing values in the original 'Date' and 'Sales' columns before aggregation (as done in cell 9) is the most critical part for the integrity of `df_daily_sales`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering from Date Index for `df_daily_sales`\n",
    "\n",
    "Creating time-based features can help models capture seasonality and trends.\n",
    "\n",
    "*   **Month:** Captures monthly seasonality (e.g., higher sales in certain months).\n",
    "*   **Year:** Helps the model understand long-term trends.\n",
    "*   **Day of the week:** Can capture weekly patterns (e.g., higher sales on weekends).\n",
    "*   **Quarter:** Captures quarterly business cycles.\n",
    "*   **Day of year:** Provides a granular view of the day within the year, useful for specific annual events.\n",
    "*   **Week of year:** Captures weekly seasonality over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering from Date Index\n",
    "df_daily_sales['Month'] = df_daily_sales.index.month\n",
    "df_daily_sales['Year'] = df_daily_sales.index.year\n",
    "df_daily_sales['DayOfWeek'] = df_daily_sales.index.dayofweek # Monday=0, Sunday=6\n",
    "df_daily_sales['Quarter'] = df_daily_sales.index.quarter\n",
    "df_daily_sales['DayOfYear'] = df_daily_sales.index.dayofyear\n",
    "df_daily_sales['WeekOfYear'] = df_daily_sales.index.isocalendar().week.astype(int)\n",
    "\n",
    "print(\"Daily sales data with new features:\")\n",
    "display(df_daily_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Model Definition, Training, and Initial Forecasting Setup\n",
    "\n",
    "This section defines the `EnhancedHybridModel` class, which combines a Gradient Boosting Regressor and an LSTM neural network. It then details the data splitting strategy, model training, and an initial example of making a short-term forecast using an interactive dropdown."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `EnhancedHybridModel` Class Definition\n",
    "\n",
    "The `EnhancedHybridModel` is designed to capture different aspects of time series data:\n",
    "-   **Gradient Boosting Regressor (GB):** Models the trend and seasonality components based on time-based features.\n",
    "-   **LSTM (Long Short-Term Memory) Network:** Models the residuals (the part of the sales data not explained by the GB model), capturing more complex non-linear patterns and temporal dependencies.\n",
    "\n",
    "**Key aspects of the model:**\n",
    "-   `gb_feature_columns`: Explicitly defines the time-based features (e.g., 'Month', 'Year', 'DayOfWeek') used by the GB model.\n",
    "-   `fit()`: Trains the GB model first, then trains the LSTM model on the residuals of the GB model's predictions.\n",
    "-   `make_future_dataframe()`: Creates a DataFrame for future dates and populates it with the required `gb_feature_columns`.\n",
    "-   `predict()`: Generates final predictions by summing the predictions from the GB model and the LSTM model.\n",
    "-   Includes methods for displaying predictions and plotting forecasts with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sales for 2025-06: 472.77\n",
      "472.7653629314859\n"
     ]
    }
   ],
   "source": [
    "# def predict_sales(selected_month):\n",
    "#     month_num = (pd.to_datetime(selected_month).year - df['Date'].dt.year.min()) * 12 + pd.to_datetime(selected_month).month\n",
    "#     pred = model.predict(np.array([[month_num]]))[0]\n",
    "#     print(f'Predicted sales for {selected_month}: {pred:.2f}')\n",
    "#     return pred\n",
    "#     predict_button = widgets.Button(description='Predict Sales')\n",
    "# def on_predict_clicked(b):\n",
    "#     predict_sales(month_dropdown.value)\n",
    "#     predict_button.on_click(on_predict_clicked)\n",
    "#     display(predict_button)\n",
    "# print(predict_sales(month_dropdown.value))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score # For GB model evaluation\n",
    "\n",
    "import matplotlib.pyplot as plt # Ensure plt is imported if not already in this cell scope\n",
    "\n",
    "class EnhancedHybridModel:\n",
    "    \"\"\"\n",
    "    Enhanced Hybrid Time Series Model combining Gradient Boosting and LSTM\n",
    "    with clear prediction display functionality.\n",
    "    \n",
    "    The Gradient Boosting model captures trend and seasonality using time-based features.\n",
    "    The LSTM model is trained on the residuals of the GB model to capture non-linear patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback=12, lstm_units=64, dropout_rate=0.2,\n",
    "                 n_estimators=100, learning_rate=0.1,\n",
    "                 epochs=100, batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the EnhancedHybridModel.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        lookback : int\n",
    "            Number of previous time steps to use as input for LSTM.\n",
    "        lstm_units : int\n",
    "            Number of units in the LSTM layers.\n",
    "        dropout_rate : float\n",
    "            Dropout rate for LSTM layers.\n",
    "        n_estimators : int\n",
    "            Number of boosting stages for GradientBoostingRegressor.\n",
    "        learning_rate : float\n",
    "            Learning rate for GradientBoostingRegressor.\n",
    "        epochs : int\n",
    "            Number of epochs for LSTM training.\n",
    "        batch_size : int\n",
    "            Batch size for LSTM training.\n",
    "        \"\"\"\n",
    "        # Model parameters\n",
    "        self.lookback = lookback\n",
    "        self.lstm_units = lstm_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialize models and scalers\n",
    "        self.lstm_model = None\n",
    "        self.gb_model = None # This will be GradientBoostingRegressor\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1)) # For scaling LSTM residuals\n",
    "        \n",
    "        # Track data properties\n",
    "        self.last_date = None # Last date seen during training\n",
    "        self.freq = None      # Frequency of the time series data\n",
    "        self.last_sequence = None # Last sequence of scaled residuals for LSTM prediction\n",
    "        \n",
    "        # Define the feature columns that the GB model will explicitly use\n",
    "        # These features are expected to be present in the input DataFrames to fit() and predict()\n",
    "        self.gb_feature_columns = ['Month', 'Year', 'DayOfWeek', 'Quarter', 'DayOfYear', 'WeekOfYear']\n",
    "        \n",
    "    # _create_time_features (original method generating features from dates) is removed as \n",
    "    # we now expect these features to be pre-calculated in the input DataFrame \n",
    "    # or specifically created in make_future_dataframe.\n",
    "\n",
    "    def _create_sequences(self, data):\n",
    "        \"\"\"Create sequence data for LSTM from scaled residuals.\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.lookback):\n",
    "            X.append(data[i:(i + self.lookback), 0]) # Input sequence\n",
    "            y.append(data[i + self.lookback, 0])    # Target value (next step)\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def _build_lstm_model(self, input_shape):\n",
    "        \"\"\"Build LSTM model architecture.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=self.lstm_units, return_sequences=True, \n",
    "                       input_shape=input_shape))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(LSTM(units=self.lstm_units//2)) # Second LSTM layer, less units\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(1)) # Output layer predicts a single value (the residual)\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "    \n",
    "    def fit(self, df_train, date_col='Date', target_col='Sales', validation_df_gb=None, verbose=1):\n",
    "        \"\"\"\n",
    "        Fit both Gradient Boosting and LSTM models to the training data.\n",
    "        \n",
    "        The GB model is trained on the specified `gb_feature_columns`.\n",
    "        The LSTM model is trained on the residuals of the GB model's predictions.\n",
    "        \"\"\"\n",
    "        if verbose > 0:\n",
    "            print(\"Preparing data for hybrid model training...\")\n",
    "        \n",
    "        df_train[date_col] = pd.to_datetime(df_train[date_col])\n",
    "\n",
    "        self.last_date = df_train[date_col].max()\n",
    "        self.freq = pd.infer_freq(df_train[date_col].sort_values())\n",
    "        if self.freq is None: # Fallback if frequency cannot be inferred\n",
    "            if len(df_train[date_col]) >= 2:\n",
    "                 # Attempt inference again if there are at least two dates\n",
    "                self.freq = pd.infer_freq(df_train[date_col].sort_values())\n",
    "            if self.freq is None: # Still None, default to 'D'\n",
    "                self.freq = 'D' \n",
    "                if verbose > 0:\n",
    "                    print(f\"Could not infer frequency from training data, defaulting to '{self.freq}'. Ensure data is regularly spaced or handle frequency explicitly.\")\n",
    "        \n",
    "        # Ensure defined feature columns are present in the training DataFrame\n",
    "        missing_cols = [col for col in self.gb_feature_columns if col not in df_train.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required feature columns in training data for GB model: {missing_cols}. These columns should be pre-engineered.\")\n",
    "        train_gb_features = df_train[self.gb_feature_columns]\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"Training Gradient Boosting model on features: {self.gb_feature_columns} with shape {train_gb_features.shape}...\")\n",
    "            \n",
    "        self.gb_model = GradientBoostingRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_depth=5, # This is an example hyperparameter; can be tuned\n",
    "            random_state=42\n",
    "        )\n",
    "        self.gb_model.fit(train_gb_features, df_train[target_col])\n",
    "        \n",
    "        # Optional: Evaluate GB model on a separate validation set for GB component, if provided\n",
    "        if validation_df_gb is not None and not validation_df_gb.empty:\n",
    "            val_missing_cols_gb = [col for col in self.gb_feature_columns if col not in validation_df_gb.columns]\n",
    "            if not val_missing_cols_gb:\n",
    "                if verbose > 0:\n",
    "                    print(f\"Evaluating GB model component on provided validation data (features: {self.gb_feature_columns})...\")\n",
    "                validation_gb_features = validation_df_gb[self.gb_feature_columns]\n",
    "                gb_val_predictions = self.gb_model.predict(validation_gb_features)\n",
    "                r2 = r2_score(validation_df_gb[target_col], gb_val_predictions)\n",
    "                if verbose > 0:\n",
    "                    print(f\"Gradient Boosting model R-squared on its validation data: {r2:.4f}\")\n",
    "            else:\n",
    "                if verbose > 0:\n",
    "                    print(f\"Warning: Validation data for GB model (validation_df_gb) is missing columns: {val_missing_cols_gb}. Skipping GB component validation.\")\n",
    "\n",
    "        # Get GB predictions on the training data to calculate residuals for LSTM training\n",
    "        gb_train_predictions = self.gb_model.predict(train_gb_features).reshape(-1, 1)\n",
    "        \n",
    "        train_residuals = df_train[target_col].values.reshape(-1, 1) - gb_train_predictions\n",
    "        scaled_train_residuals = self.scaler.fit_transform(train_residuals)\n",
    "        \n",
    "        X_lstm_train, y_lstm_train = self._create_sequences(scaled_train_residuals)\n",
    "        if len(X_lstm_train) == 0:\n",
    "            raise ValueError(f\"Not enough data in training set to create LSTM sequences with lookback {self.lookback}. Need at least {self.lookback + 1} data points after GB processing.\")\n",
    "        X_lstm_train = X_lstm_train.reshape(X_lstm_train.shape[0], X_lstm_train.shape[1], 1)\n",
    "        \n",
    "        self.last_sequence = scaled_train_residuals[-self.lookback:].reshape(1, self.lookback, 1)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"Training LSTM model on residuals of shape {X_lstm_train.shape}...\")\n",
    "            \n",
    "        self.lstm_model = self._build_lstm_model((X_lstm_train.shape[1], 1))\n",
    "        \n",
    "        # Callbacks for LSTM training\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=(1 if verbose > 1 else 0)),\n",
    "            # ModelCheckpoint('enhanced_hybrid_model_lstm.h5', save_best_only=True, monitor='val_loss') # Optional: save best LSTM model\n",
    "        ]\n",
    "        \n",
    "        self.lstm_model.fit(\n",
    "            X_lstm_train, y_lstm_train,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=0.2, # Uses last 20% of LSTM sequence data for Keras internal validation\n",
    "            verbose=(1 if verbose > 1 else 0),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(\"EnhancedHybridModel (GB+LSTM) training complete!\")\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def make_future_dataframe(self, periods):\n",
    "        \"\"\"\n",
    "        Create a dataframe of future dates for forecasting, including required features.\n",
    "        \"\"\"\n",
    "        if self.last_date is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions to know the last date of training.\")\n",
    "            \n",
    "        future_dates = pd.date_range(\n",
    "            start=self.last_date + pd.Timedelta(days=1 if self.freq == 'D' else pd.Timedelta(self.freq)),\n",
    "            periods=periods,\n",
    "            freq=self.freq\n",
    "        )\n",
    "        future_df = pd.DataFrame({'ds': future_dates})\n",
    "        \n",
    "        # Add the GB feature columns. 'ds' is used as the source of date information.\n",
    "        # This assumes gb_feature_columns are derived from the date.\n",
    "        temp_date_series = pd.to_datetime(future_df['ds'])\n",
    "        future_df['Month'] = temp_date_series.dt.month\n",
    "        future_df['Year'] = temp_date_series.dt.year\n",
    "        future_df['DayOfWeek'] = temp_date_series.dt.dayofweek\n",
    "        future_df['Quarter'] = temp_date_series.dt.quarter\n",
    "        future_df['DayOfYear'] = temp_date_series.dt.dayofyear\n",
    "        future_df['WeekOfYear'] = temp_date_series.dt.isocalendar().week.astype(int)\n",
    "        \n",
    "        # Ensure all columns defined in self.gb_feature_columns are present\n",
    "        for col in self.gb_feature_columns:\n",
    "            if col not in future_df.columns:\n",
    "                # This case should ideally not be hit if gb_feature_columns only contains date-derivable features\n",
    "                raise ValueError(f\"Feature column '{col}' was not generated in make_future_dataframe. Check logic.\")\n",
    "        return future_df\n",
    "    \n",
    "    def predict(self, future_df=None, periods=None):\n",
    "        \"\"\"\n",
    "        Generate predictions with the hybrid model.\n",
    "        `future_df` must contain a 'ds' column with dates and all columns listed in `self.gb_feature_columns`.\n",
    "        \"\"\"\n",
    "        if self.lstm_model is None or self.gb_model is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions.\")\n",
    "            \n",
    "        if future_df is None and periods is not None:\n",
    "            future_df = self.make_future_dataframe(periods) # This will have 'ds' and gb_feature_columns\n",
    "        elif future_df is None and periods is None:\n",
    "            raise ValueError(\"Either `future_df` (with 'ds' and feature columns) or `periods` must be provided.\")\n",
    "        \n",
    "        # Ensure future_df has the required 'ds' and feature columns\n",
    "        if 'ds' not in future_df.columns:\n",
    "            raise ValueError(\"future_df must contain a 'ds' column with dates.\")\n",
    "        missing_future_cols = [col for col in self.gb_feature_columns if col not in future_df.columns]\n",
    "        if missing_future_cols:\n",
    "            raise ValueError(f\"Missing required feature columns in future_df for GB prediction: {missing_future_cols}. Ensure make_future_dataframe populates these or they are in the provided future_df.\")\n",
    "            \n",
    "        future_gb_features = future_df[self.gb_feature_columns]\n",
    "        gb_predictions = self.gb_model.predict(future_gb_features).reshape(-1, 1)\n",
    "        \n",
    "        lstm_forecasts = []\n",
    "        current_sequence = self.last_sequence.copy()\n",
    "        \n",
    "        for _ in range(len(future_df)):\n",
    "            next_pred_scaled = self.lstm_model.predict(current_sequence, verbose=0)\n",
    "            lstm_forecasts.append(next_pred_scaled[0, 0])\n",
    "            current_sequence = np.append(current_sequence[:, 1:, :], [[next_pred_scaled[0, 0]]], axis=1)\n",
    "        \n",
    "        lstm_forecasts_unscaled = self.scaler.inverse_transform(np.array(lstm_forecasts).reshape(-1, 1))\n",
    "        \n",
    "        final_forecasts = gb_predictions + lstm_forecasts_unscaled\n",
    "        \n",
    "        forecast_df_out = future_df[['ds']].copy() # Start with 'ds' column from input future_df\n",
    "        forecast_df_out['yhat'] = final_forecasts\n",
    "        forecast_df_out['trend'] = gb_predictions\n",
    "        forecast_df_out['residual'] = lstm_forecasts_unscaled\n",
    "        \n",
    "        # Calculate confidence intervals (simplified)\n",
    "        residual_std_dev = 0 # Default\n",
    "        if self.last_sequence is not None and len(self.last_sequence) > 0:\n",
    "            lstm_pred_on_last_seq_scaled = self.lstm_model.predict(self.last_sequence, verbose=0)\n",
    "            unscaled_lstm_pred_on_last_seq = self.scaler.inverse_transform(lstm_pred_on_last_seq_scaled)\n",
    "            residual_std_dev = np.std(unscaled_lstm_pred_on_last_seq) \n",
    "        else:\n",
    "            # Fallback if last_sequence is not available (e.g., model loaded without it)\n",
    "            # This would ideally use residuals from training/validation if stored, or from current forecasts\n",
    "            if len(lstm_forecasts_unscaled) > 1:\n",
    "                residual_std_dev = np.std(lstm_forecasts_unscaled)\n",
    "            else: # Cannot compute std dev from a single forecast point\n",
    "                residual_std_dev = 0 # Or some other sensible default/warning\n",
    "            \n",
    "        forecast_df_out['yhat_lower'] = forecast_df_out['yhat'] - 1.96 * residual_std_dev\n",
    "        forecast_df_out['yhat_upper'] = forecast_df_out['yhat'] + 1.96 * residual_std_dev\n",
    "        \n",
    "        return forecast_df_out\n",
    "    \n",
    "    def display_prediction_for_month(self, forecast_df, target_date):\n",
    "        \"\"\"\n",
    "        Display the prediction for a specific date clearly.\n",
    "        Assumes `forecast_df` is output from `predict()` method.\n",
    "        \"\"\"\n",
    "        if isinstance(target_date, str):\n",
    "            target_date = pd.to_datetime(target_date)\n",
    "            \n",
    "        forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "        selected_forecast = forecast_df[forecast_df['ds'].dt.normalize() == target_date.normalize()]\n",
    "        \n",
    "        if selected_forecast.empty:\n",
    "            print(f\"⚠️ No forecast available for {target_date.strftime('%Y-%m-%d')}. Ensure the date is within the forecast range and is a valid forecast date.\")\n",
    "            return None\n",
    "        \n",
    "        # Get prediction values for the first (and should be only) row for that date\n",
    "        prediction_row = selected_forecast.iloc[0]\n",
    "        predicted_value = prediction_row['yhat']\n",
    "        trend_component = prediction_row['trend']\n",
    "        residual_component = prediction_row['residual']\n",
    "        lower_bound = prediction_row['yhat_lower']\n",
    "        upper_bound = prediction_row['yhat_upper']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"📊 FORECAST FOR {target_date.strftime('%B %d, %Y').upper()}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"📈 Predicted Sales       : {predicted_value:.2f}\")\n",
    "        print(f\"⚖️ Confidence Interval : [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(\"\\nComponent Breakdown:\")\n",
    "        print(f\"    🔹 Trend/Seasonal (GB) : {trend_component:.2f} ({(trend_component/predicted_value*100 if predicted_value != 0 else 0):.1f}%)\")\n",
    "        print(f\"    🔹 Residual (LSTM)     : {residual_component:.2f} ({(residual_component/predicted_value*100 if predicted_value != 0 else 0):.1f}%)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'date': target_date,\n",
    "            'prediction': predicted_value,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'trend': trend_component,\n",
    "            'residual': residual_component\n",
    "        }\n",
    "    \n",
    "    def plot_forecast(self, forecast_df, historical_df=None, \n",
    "                     date_col='Date', target_col='Sales',\n",
    "                     highlight_date=None):\n",
    "        \"\"\"\n",
    "        Plot the forecast with optional historical data.\n",
    "        `historical_df` should have `date_col` and `target_col`.\n",
    "        `forecast_df` should have 'ds', 'yhat', 'yhat_lower', 'yhat_upper'.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 8)) # Slightly larger plot for better readability\n",
    "        \n",
    "        # Plot historical data if provided and not empty\n",
    "        if historical_df is not None and not historical_df.empty:\n",
    "            plt.plot(pd.to_datetime(historical_df[date_col]), historical_df[target_col],\n",
    "                    color='royalblue', linewidth=2, label='Historical Sales Data', alpha=0.8)\n",
    "            \n",
    "            # Add vertical line separating historical and forecast periods\n",
    "            last_historical_date = pd.to_datetime(historical_df[date_col]).max()\n",
    "            plt.axvline(x=last_historical_date, color='grey', linestyle='--', linewidth=1.2, alpha=0.7, label=f'End of History ({last_historical_date.strftime(\"%Y-%m-%d\")})')\n",
    "        \n",
    "        # Plot forecast\n",
    "        plt.plot(pd.to_datetime(forecast_df['ds']), forecast_df['yhat'],\n",
    "                color='darkorange', linewidth=2, linestyle='--', label='Forecasted Sales (yhat)')\n",
    "        \n",
    "        # Plot confidence interval\n",
    "        plt.fill_between(pd.to_datetime(forecast_df['ds']),\n",
    "                        forecast_df['yhat_lower'],\n",
    "                        forecast_df['yhat_upper'],\n",
    "                        alpha=0.2, color='darkorange', label='95% Confidence Interval')\n",
    "        \n",
    "        # Highlight specific date if provided\n",
    "        if highlight_date is not None:\n",
    "            highlight_date = pd.to_datetime(highlight_date)\n",
    "            # Find the forecast for the specific date (normalize to compare dates only)\n",
    "            highlight_forecast_row = forecast_df[pd.to_datetime(forecast_df['ds']).dt.normalize() == highlight_date.normalize()]\n",
    "            if not highlight_forecast_row.empty:\n",
    "                plt.scatter(highlight_date, highlight_forecast_row['yhat'].values[0],\n",
    "                          color='red', s=100, zorder=5, label=f'Specific Forecast: {highlight_date.strftime(\"%b %d, %Y\")}')\n",
    "        \n",
    "        plt.title('Sales Forecast: Historical Data & Predictions', fontsize=18)\n",
    "        plt.xlabel('Date', fontsize=14)\n",
    "        plt.ylabel('Sales', fontsize=14)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle=':', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt\n",
    "\n",
    "# The commented out section below is an example of how to use the model.\n",
    "# It has been moved to the cell where the model is actually trained and used.\n",
    "\"\"\"\n",
    "# # Prepare data\n",
    "# df_daily_sales_reset = df_daily_sales.reset_index() # Ensure 'Date' is a column\n",
    "# \n",
    "# # Initialize and train the hybrid model\n",
    "# model = EnhancedHybridModel(\n",
    "#     lookback=12,\n",
    "#     lstm_units=64,\n",
    "#     dropout_rate=0.2,\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.05,\n",
    "#     epochs=50\n",
    "# )\n",
    "# model.fit(df_daily_sales_reset, date_col='Date', target_col='Sales')\n",
    "# \n",
    "# # Get selected month from dropdown\n",
    "# future_date = pd.to_datetime(month_dropdown.value)\n",
    "# \n",
    "# # Create future dataframe and generate forecast\n",
    "# future = model.make_future_dataframe(periods=36)\n",
    "# forecast = model.predict(future)\n",
    "# \n",
    "# # Display prediction for selected month\n",
    "# prediction_info = model.display_prediction_for_month(forecast, future_date)\n",
    "# \n",
    "# # Visualize the forecast\n",
    "# model.plot_forecast(forecast, historical_df=df_daily_sales_reset, date_col='Date', target_col='Sales', highlight_date=future_date)\n",
    "# plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Feature Usage Clarification:\n",
    "\n",
    "**How it works now:**\n",
    "1.  **Feature Engineering Cell (Index 13):** These six features are explicitly created in the `df_daily_sales` DataFrame.\n",
    "2.  **Data Splitting (Cell Index 16):** `train_df` and `validation_df` are derived from `df_daily_sales` and therefore contain these feature columns.\n",
    "3.  **Model `fit` Method:** The `EnhancedHybridModel.fit()` method is now configured to select these specific columns from the input `train_df` to train its internal Gradient Boosting model. It will raise an error if these columns are missing.\n",
    "4.  **Model `make_future_dataframe` Method:** This method now also generates these six standard time features for any future dates it creates, ensuring consistency for the `predict` method.\n",
    "5.  **Model `predict` Method:** When making predictions, the model uses these same six features from the `future_df` (which should have been prepared by `make_future_dataframe`).\n",
    "\n",
    "This ensures that the time-based features manually specified and created in the notebook are directly utilized by the Gradient Boosting part of the hybrid model.\n",
    "\n",
    "The LSTM component of the model continues to be trained on the residuals derived from this Gradient Boosting model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the EnhancedHybridModel (GB + LSTM)\n",
    "\n",
    "# 1. Implement Train/Validation Split\n",
    "# Ensure df_daily_sales is sorted by date if not already (it should be from previous steps)\n",
    "df_daily_sales_for_split = df_daily_sales.copy() # Use the version with Date as index and features\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_point = int(len(df_daily_sales_for_split) * split_ratio)\n",
    "\n",
    "# Perform the split using iloc. Since the DataFrame is time-indexed and sorted,\n",
    "# this correctly splits by time.\n",
    "train_df_indexed = df_daily_sales_for_split.iloc[:split_point]\n",
    "validation_df_indexed = df_daily_sales_for_split.iloc[split_point:]\n",
    "\n",
    "print(f\"Training data shape (indexed): {train_df_indexed.shape}\")\n",
    "print(f\"Validation data shape (indexed): {validation_df_indexed.shape}\")\n",
    "\n",
    "if not train_df_indexed.empty:\n",
    "    print(\"Training data head (indexed):\")\n",
    "    display(train_df_indexed.head())\n",
    "if not validation_df_indexed.empty:\n",
    "    print(\"Validation data head (indexed):\")\n",
    "    display(validation_df_indexed.head())\n",
    "\n",
    "# Reset index for model compatibility, as the model expects 'Date' as a column\n",
    "train_df = train_df_indexed.reset_index()\n",
    "validation_df = validation_df_indexed.reset_index()\n",
    "\n",
    "print(f\"\\nTraining data shape (Date as column): {train_df.shape}\")\n",
    "print(f\"Validation data shape (Date as column): {validation_df.shape}\")\n",
    "if not train_df.empty:\n",
    "    print(\"Training data head (Date as column):\")\n",
    "    display(train_df.head())\n",
    "if not validation_df.empty:\n",
    "    print(\"Validation data head (Date as column):\")\n",
    "    display(validation_df.head())\n",
    "\n",
    "gb_lstm_model = EnhancedHybridModel(\n",
    "    lookback=12,  # Consider if 12 (days) is appropriate for daily data context\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.2,\n",
    "    n_estimators=100, # For GradientBoostingRegressor\n",
    "    learning_rate=0.05, # For GradientBoostingRegressor\n",
    "    epochs=50, # For LSTM training\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nFitting EnhancedHybridModel (GB + LSTM) with train_df and validating GB part with validation_df...\")\n",
    "if not train_df.empty and 'Date' in train_df.columns and 'Sales' in train_df.columns:\n",
    "    # For validation_df_gb, ensure it also has 'Date' and 'Sales' columns if not empty\n",
    "    validation_gb_ready = validation_df if not validation_df.empty and 'Date' in validation_df.columns and 'Sales' in validation_df.columns else None\n",
    "    gb_lstm_model.fit(train_df, date_col='Date', target_col='Sales', validation_df_gb=validation_gb_ready, verbose=1)\n",
    "    print(\"Model training complete.\")\n",
    "else:\n",
    "    print(\"Skipping model training as training dataframe is empty or missing 'Date'/'Sales' columns after split.\")\n",
    "\n",
    "# Prediction and plotting for future dates (using month_dropdown)\n",
    "# Ensure train_df used for historical_df in plot_forecast has 'Date' as a column for consistency with model's expectations\n",
    "if 'gb_lstm_model' in locals() and gb_lstm_model.gb_model is not None and not train_df.empty(): # Check if model was trained\n",
    "    print(\"\\n--- Future Forecast (using month_dropdown) ---\")\n",
    "    if 'month_dropdown' in locals():\n",
    "    future_date_to_predict = pd.to_datetime(month_dropdown.value)\n",
    "else:\n",
    "    # Fallback if dropdown not found (e.g. running non-interactively)\n",
    "        future_date_to_predict = pd.to_datetime('2025-01-01') \n",
    "        print(f\"Warning: month_dropdown not found, using fallback date {future_date_to_predict.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Create future dataframe and generate forecast\n",
    "    future_df = gb_lstm_model.make_future_dataframe(periods=12) # Predict 12 periods into the future\n",
    "    forecast_df_future = gb_lstm_model.predict(future_df)\n",
    "\n",
    "    # Display prediction for the selected/fallback month\n",
    "    prediction_info = gb_lstm_model.display_prediction_for_month(forecast_df_future, future_date_to_predict)\n",
    "\n",
    "    # Visualize the forecast - using train_df as historical_df for this future forecast plot\n",
    "    fig = gb_lstm_model.plot_forecast(forecast_df_future, historical_df=train_df, date_col='Date', target_col='Sales', highlight_date=future_date_to_predict)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model was not trained or train_df is empty, skipping future prediction and plotting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Validation Split and Model Fitting\n",
    "\n",
    "The `df_daily_sales` data (with engineered features) is split into training and validation sets. The `EnhancedHybridModel` is then initialized and trained using the training data. The validation data is used by the model's internal GB component for early stopping if parameters were set for that, or for optional R2 score calculation as implemented.\n",
    "\n",
    "An example forecast using an interactive dropdown for selecting a month is also included to demonstrate the model's `predict` and `display_prediction_for_month` methods immediately after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the EnhancedHybridModel (GB + LSTM)\n",
    "\n",
    "# 1. Implement Train/Validation Split\n",
    "# Ensure df_daily_sales is sorted by date if not already (it should be from previous steps)\n",
    "df_daily_sales_for_split = df_daily_sales.copy() # Use the version with Date as index and features\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_point = int(len(df_daily_sales_for_split) * split_ratio)\n",
    "\n",
    "# Perform the split using iloc. Since the DataFrame is time-indexed and sorted,\n",
    "# this correctly splits by time.\n",
    "train_df_indexed = df_daily_sales_for_split.iloc[:split_point]\n",
    "validation_df_indexed = df_daily_sales_for_split.iloc[split_point:]\n",
    "\n",
    "print(f\"Training data shape (indexed): {train_df_indexed.shape}\")\n",
    "print(f\"Validation data shape (indexed): {validation_df_indexed.shape}\")\n",
    "\n",
    "if not train_df_indexed.empty:\n",
    "    print(\"Training data head (indexed):\")\n",
    "    display(train_df_indexed.head())\n",
    "if not validation_df_indexed.empty:\n",
    "    print(\"Validation data head (indexed):\")\n",
    "    display(validation_df_indexed.head())\n",
    "\n",
    "# Reset index for model compatibility, as the model expects 'Date' as a column\n",
    "train_df = train_df_indexed.reset_index()\n",
    "validation_df = validation_df_indexed.reset_index()\n",
    "\n",
    "print(f\"\\nTraining data shape (Date as column): {train_df.shape}\")\n",
    "print(f\"Validation data shape (Date as column): {validation_df.shape}\")\n",
    "if not train_df.empty:\n",
    "    print(\"Training data head (Date as column):\")\n",
    "    display(train_df.head())\n",
    "if not validation_df.empty:\n",
    "    print(\"Validation data head (Date as column):\")\n",
    "    display(validation_df.head())\n",
    "\n",
    "gb_lstm_model = EnhancedHybridModel(\n",
    "    lookback=12,  # Consider if 12 (days) is appropriate for daily data context\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.2,\n",
    "    n_estimators=100, # For GradientBoostingRegressor\n",
    "    learning_rate=0.05, # For GradientBoostingRegressor\n",
    "    epochs=50, # For LSTM training\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nFitting EnhancedHybridModel (GB + LSTM) with train_df and validating GB part with validation_df...\")\n",
    "if not train_df.empty and 'Date' in train_df.columns and 'Sales' in train_df.columns:\n",
    "    # For validation_df_gb, ensure it also has 'Date' and 'Sales' columns if not empty\n",
    "    validation_gb_ready = validation_df if not validation_df.empty and 'Date' in validation_df.columns and 'Sales' in validation_df.columns else None\n",
    "    gb_lstm_model.fit(train_df, date_col='Date', target_col='Sales', validation_df_gb=validation_gb_ready, verbose=1)\n",
    "    print(\"Model training complete.\")\n",
    "else:\n",
    "    print(\"Skipping model training as training dataframe is empty or missing 'Date'/'Sales' columns after split.\")\n",
    "\n",
    "# Prediction and plotting for future dates (using month_dropdown)\n",
    "# Ensure train_df used for historical_df in plot_forecast has 'Date' as a column for consistency with model's expectations\n",
    "if 'gb_lstm_model' in locals() and gb_lstm_model.gb_model is not None and not train_df.empty(): # Check if model was trained\n",
    "    print(\"\\n--- Future Forecast (using month_dropdown) ---\")\n",
    "    if 'month_dropdown' in locals():\n",
    "        future_date_to_predict = pd.to_datetime(month_dropdown.value)\n",
    "    else:\n",
    "        # Fallback if dropdown not found (e.g. running non-interactively)\n",
    "        future_date_to_predict = pd.to_datetime('2025-01-01') \n",
    "        print(f\"Warning: month_dropdown not found, using fallback date {future_date_to_predict.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Create future dataframe and generate forecast for a short period (e.g., 12 months or days)\n",
    "    # Note: The EnhancedHybridModel's make_future_dataframe creates periods starting from the day AFTER gb_lstm_model.last_date\n",
    "    future_df_interactive = gb_lstm_model.make_future_dataframe(periods=365) # Example: forecast for 1 year for dropdown interaction\n",
    "    forecast_df_interactive = gb_lstm_model.predict(future_df_interactive)\n",
    "\n",
    "    # Display prediction for the selected/fallback month from this forecast\n",
    "    prediction_info_interactive = gb_lstm_model.display_prediction_for_month(forecast_df_interactive, future_date_to_predict)\n",
    "\n",
    "    # Visualize the forecast - using train_df as historical_df for this future forecast plot\n",
    "    # Plot a limited range for clarity, e.g., historical data + 1 year of forecast\n",
    "    fig_interactive = gb_lstm_model.plot_forecast(\n",
    "        forecast_df=forecast_df_interactive, \n",
    "        historical_df=train_df, \n",
    "        date_col='Date', \n",
    "        target_col='Sales', \n",
    "        highlight_date=future_date_to_predict\n",
    "    )\n",
    "    # Limit x-axis for better readability of interactive forecast plot\n",
    "    if not forecast_df_interactive.empty:\n",
    "        interactive_plot_end_date = min(forecast_df_interactive['ds'].max(), train_df['Date'].max() + pd.Timedelta(days=180)) # Show approx 6 months of forecast\n",
    "        plt.xlim([train_df['Date'].min() - pd.Timedelta(days=30), interactive_plot_end_date])\n",
    "    plt.title(f\"Interactive Forecast Demo (Selected: {future_date_to_predict.strftime('%Y-%m')})\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model was not trained or train_df is empty, skipping future prediction and plotting for interactive demo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Evaluation on Validation Set\n",
    "\n",
    "After training the `EnhancedHybridModel`, it's crucial to evaluate its performance on unseen data (the validation set). This helps to understand how well the model generalizes to new data it hasn't been trained on.\n",
    "\n",
    "**Evaluation Process:**\n",
    "1.  **Prediction:** The trained model (`gb_lstm_model`) is used to generate sales predictions for the dates in the `validation_df`.\n",
    "2.  **Comparison:** These predictions (`yhat`) are then compared against the actual sales figures (`Sales`) from the `validation_df`.\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "\n",
    "Several standard time series forecasting metrics are calculated to quantify the model's accuracy:\n",
    "\n",
    "*   **Mean Absolute Error (MAE):** Measures the average magnitude of the errors in a set of predictions, without considering their direction. It's the average over the validation sample of the absolute differences between prediction and actual observation where all individual differences have equal weight. Formula: `(1/n) * Σ|Actual - Predicted|`\n",
    "*   **Root Mean Squared Error (RMSE):** Is the square root of the average of squared differences between prediction and actual observation. RMSE penalizes large errors more heavily than MAE. Formula: `sqrt((1/n) * Σ(Actual - Predicted)^2)`\n",
    "*   **Mean Absolute Percentage Error (MAPE):** Measures the average absolute percentage difference between the predicted and actual values. It's useful for understanding the error in relative terms. Formula: `(1/n) * Σ(|Actual - Predicted| / |Actual|) * 100` (Note: Care must be taken when actual values are zero or close to zero, as this can lead to undefined or extremely large MAPE values. The implementation below includes a check for this.)\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "*   Lower values for MAE, RMSE, and MAPE generally indicate better model performance.\n",
    "*   The choice of which metric is most important can depend on the business context (e.g., whether large errors are disproportionately costly).\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "A plot is generated to visually compare:\n",
    "*   Historical training data (for context).\n",
    "*   Actual sales values from the validation set.\n",
    "*   Predicted sales values on the validation set.\n",
    "\n",
    "This visualization helps in qualitatively assessing how well the model's predictions track the actual sales, identify patterns in errors (e.g., systematic over or under-prediction), and understand the model's behavior during the validation period.\n",
    "\n",
    "**Note on `validation_df_gb` in `fit()` method:** The `EnhancedHybridModel.fit()` method has an optional `validation_df_gb` parameter. If provided during training (as it is in cell 16), the GB component's R-squared score on this validation data is printed. This is a preliminary check on the GB part. The main evaluation in this current cell, however, assesses the performance of the *entire hybrid model* (GB + LSTM) on the `validation_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "if 'gb_lstm_model' in locals() and gb_lstm_model.gb_model is not None and not validation_df.empty:\n",
    "    print(\"--- Evaluating Model on Validation Set ---\")\n",
    "    \n",
    "    # Prepare validation_df for the model's predict method.\n",
    "    # The predict method expects a DataFrame with a 'ds' column (for dates)\n",
    "    # and all columns listed in gb_lstm_model.gb_feature_columns.\n",
    "    validation_df_for_predict = validation_df.copy()\n",
    "    validation_df_for_predict.rename(columns={'Date': 'ds'}, inplace=True)\n",
    "    # Ensure all required feature columns are present (they should be from the split)\n",
    "    missing_eval_cols = [col for col in gb_lstm_model.gb_feature_columns if col not in validation_df_for_predict.columns]\n",
    "    if missing_eval_cols:\n",
    "        print(f\"ERROR: Missing feature columns in validation_df_for_predict: {missing_eval_cols}\")\n",
    "    else:\n",
    "        # Generate predictions for the validation period\n",
    "        print(f\"Generating predictions for validation set of shape {validation_df_for_predict.shape}...\")\n",
    "        validation_forecast_df = gb_lstm_model.predict(future_df=validation_df_for_predict)\n",
    "    \n",
    "        # Merge predictions with actuals from validation_df for easy comparison\n",
    "        # Ensure 'Date' in validation_df is comparable with 'ds' in validation_forecast_df\n",
    "        validation_forecast_df['ds'] = pd.to_datetime(validation_forecast_df['ds'])\n",
    "        # validation_df['Date'] is already datetime from previous steps\n",
    "        results_df = pd.merge(validation_df, validation_forecast_df[['ds', 'yhat']], left_on='Date', right_on='ds', how='left')\n",
    "\n",
    "        if results_df['yhat'].isnull().any():\n",
    "        print(\"Warning: Could not map all predictions to validation actuals. Check date alignment.\")\n",
    "        # Display for debugging\n",
    "        # print(\"Validation DF (Date):\")\n",
    "        # print(validation_df[['Date']].head())\n",
    "        # print(\"Validation Forecast DF (ds):\")\n",
    "        # print(validation_forecast_df[['ds']].head())\n",
    "        # print(\"Merged Results DF sample:\")\n",
    "        # print(results_df[results_df['yhat'].isnull()].head())\n",
    "    \n",
    "    # Filter out rows where predictions might be NaN due to merge issues or otherwise\n",
    "    results_df.dropna(subset=['Sales', 'yhat'], inplace=True)\n",
    "\n",
    "    actuals = results_df['Sales']\n",
    "    predictions = results_df['yhat']\n",
    "\n",
    "    if not actuals.empty and not predictions.empty:\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # MAPE calculation with protection against division by zero\n",
    "        abs_error = np.abs(actuals - predictions)\n",
    "        abs_actuals_safe = np.where(actuals == 0, 1e-6, actuals) # Avoid division by zero\n",
    "        mape = np.mean(abs_error / np.abs(abs_actuals_safe)) * 100\n",
    "        \n",
    "        print(f\"Validation MAE: {mae:.4f}\")\n",
    "        print(f\"Validation MSE: {mse:.4f}\")\n",
    "        print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "        print(f\"Validation MAPE: {mape:.2f}%\")\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        if 'train_df' in locals() and not train_df.empty:\n",
    "            plt.plot(train_df['Date'], train_df['Sales'], label='Training Data', color='blue')\n",
    "        plt.plot(results_df['Date'], results_df['Sales'], label='Actual Validation Sales', color='green')\n",
    "        plt.plot(results_df['Date'], results_df['yhat'], label='Predicted Validation Sales', color='red', linestyle='--')\n",
    "        \n",
    "        # Optionally plot trend and residuals if desired, from validation_forecast_df\n",
    "            # plt.plot(validation_forecast_df['ds'], validation_forecast_df['trend'], label='Validation Trend (GB)', linestyle=':')\n",
    "        \n",
    "            plt.title('Model Evaluation: Actual vs. Predicted Sales on Validation Set')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Sales')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No valid actuals or predictions to evaluate after merging and NA drop.\")\n",
    "else:\n",
    "    print(\"Model not trained or validation_df is empty / missing columns. Skipping evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This was the old Linear Regression cell
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b990d81a2423489d4e760e7de2ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Month:', options=('2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06', '202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell previously contained the LinearRegression model preparation and fitting.\n",
    "# It's commented out as per instructions to focus on EnhancedHybridModel with df_daily_sales.\n",
    "# Ensure 'Date' is datetime and 'Sales' is numeric\n",
    "# df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "# df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "#\n",
    "# Drop rows where 'Date' or 'Sales' is NaN\n",
    "# df = df.dropna(subset=['Date', 'Sales'])\n",
    "#\n",
    "# Calculate Month_Num\n",
    "# df['Month_Num'] = (df['Date'].dt.year - df['Date'].dt.year.min()) * 12 + df['Date'].dt.month\n",
    "#\n",
    "# Drop rows where 'Month_Num' is NaN (shouldn't happen, but just in case)\n",
    "# df = df.dropna(subset=['Month_Num'])\n",
    "#\n",
    "# X = df['Month_Num'].values.reshape(-1, 1)\n",
    "# y = df['Sales'].values\n",
    "#\n",
    "# Final check for NaNs\n",
    "# if np.isnan(X).any() or np.isnan(y).any():\n",
    "#     raise ValueError(\"There are still NaNs in the input data. Please check your data.\")\n",
    "#\n",
    "# model = LinearRegression()\n",
    "# model.fit(X, y)\n",
    "print(\"Old LinearRegression model cell - now commented out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This cell now contains the month_dropdown
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b990d81a2423489d4e760e7de2ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Month:', options=('2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06', '202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months_2025 = [f'2025-{str(m).zfill(2)}' for m in range(1, 13)]\n",
    "month_dropdown = widgets.Dropdown(options=months_2025, description='Month:')\n",
    "display(month_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This cell has the GB+LSTM model definition
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sales for 2025-06: 472.77\n",
      "472.7653629314859\n"
     ]
    }
   ],
   "source": [
    "# def predict_sales(selected_month):\n",
    "#     month_num = (pd.to_datetime(selected_month).year - df['Date'].dt.year.min()) * 12 + pd.to_datetime(selected_month).month\n",
    "#     pred = model.predict(np.array([[month_num]]))[0]\n",
    "#     print(f'Predicted sales for {selected_month}: {pred:.2f}')\n",
    "#     return pred\n",
    "#     predict_button = widgets.Button(description='Predict Sales')\n",
    "# def on_predict_clicked(b):\n",
    "#     predict_sales(month_dropdown.value)\n",
    "#     predict_button.on_click(on_predict_clicked)\n",
    "#     display(predict_button)\n",
    "# print(predict_sales(month_dropdown.value))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score # For GB model evaluation\n",
    "\n",
    "import matplotlib.pyplot as plt # Ensure plt is imported if not already in this cell scope\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the EnhancedHybridModel (GB + LSTM)\n",
    "gb_lstm_model = EnhancedHybridModel(\n",
    "    lookback=12,  # Example: look back 12 months\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.2,\n",
    "    n_estimators=100, # For GradientBoostingRegressor\n",
    "    learning_rate=0.05, # For GradientBoostingRegressor\n",
    "    epochs=50, # For LSTM training\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Fitting EnhancedHybridModel (GB + LSTM) with df_daily_sales...\")\n",
    "# Ensure df_daily_sales has 'Date' as a column, not an index\n",
    "if isinstance(df_daily_sales.index, pd.DatetimeIndex):\n",
    "    df_daily_sales_fit = df_daily_sales.reset_index()\n",
    "else:\n",
    "    df_daily_sales_fit = df_daily_sales.copy()\n",
    "\n",
    "gb_lstm_model.fit(df_daily_sales_fit, date_col='Date', target_col='Sales', verbose=1)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Get selected month from dropdown (ensure month_dropdown is defined and displayed earlier)\n",
    "if 'month_dropdown' in locals():\n",
    "    future_date_to_predict = pd.to_datetime(month_dropdown.value)\n",
    "else:\n",
    "    # Fallback if dropdown not found (e.g. running non-interactively)\n",
    "    future_date_to_predict = pd.to_datetime('2025-01-01') \n",
    "    print(f\"Warning: month_dropdown not found, using fallback date {future_date_to_predict.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Create future dataframe and generate forecast\n",
    "future_df = gb_lstm_model.make_future_dataframe(periods=12) # Predict 12 periods into the future\n",
    "forecast_df = gb_lstm_model.predict(future_df)\n",
    "\n",
    "# Display prediction for the selected/fallback month\n",
    "prediction_info = gb_lstm_model.display_prediction_for_month(forecast_df, future_date_to_predict)\n",
    "\n",
    "# Visualize the forecast\n",
    "fig = gb_lstm_model.plot_forecast(forecast_df, historical_df=df_daily_sales_fit, date_col='Date', target_col='Sales', highlight_date=future_date_to_predict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This was the old Linear Regression cell
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b990d81a2423489d4e760e7de2ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Month:', options=('2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06', '202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell previously contained the LinearRegression model preparation and fitting.\n",
    "# It's commented out as per instructions to focus on EnhancedHybridModel with df_daily_sales.\n",
    "# Ensure 'Date' is datetime and 'Sales' is numeric\n",
    "# df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "# df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "#\n",
    "# Drop rows where 'Date' or 'Sales' is NaN\n",
    "# df = df.dropna(subset=['Date', 'Sales'])\n",
    "#\n",
    "# Calculate Month_Num\n",
    "# df['Month_Num'] = (df['Date'].dt.year - df['Date'].dt.year.min()) * 12 + df['Date'].dt.month\n",
    "#\n",
    "# Drop rows where 'Month_Num' is NaN (shouldn't happen, but just in case)\n",
    "# df = df.dropna(subset=['Month_Num'])\n",
    "#\n",
    "# X = df['Month_Num'].values.reshape(-1, 1)\n",
    "# y = df['Sales'].values\n",
    "#\n",
    "# Final check for NaNs\n",
    "# if np.isnan(X).any() or np.isnan(y).any():\n",
    "#     raise ValueError(\"There are still NaNs in the input data. Please check your data.\")\n",
    "#\n",
    "# model = LinearRegression()\n",
    "# model.fit(X, y)\n",
    "print(\"Old LinearRegression model cell - now commented out.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Q2 2025 Sales Prediction\n",
    "\n",
    "This section focuses on forecasting sales for the second quarter of 2025 (April 1 to June 30).\n",
    "\n",
    "**Forecasting Process:**\n",
    "\n",
    "1.  **Determine Forecast Range:** The period for Q2 2025 is defined. The number of days to forecast is calculated from the end of the model's training data (`gb_lstm_model.last_date`) up to June 30, 2025.\n",
    "2.  **Generate Future DataFrame:** The `gb_lstm_model.make_future_dataframe(periods=...)` method is used. This method creates a DataFrame containing future dates and populates it with all the necessary feature columns (`Month`, `Year`, `DayOfWeek`, `Quarter`, `DayOfYear`, `WeekOfYear`) required by the Gradient Boosting component of the model.\n",
    "3.  **Make Predictions:** The `gb_lstm_model.predict()` method is called with this future DataFrame to obtain sales forecasts (`yhat`), trend components, residual components, and confidence intervals (`yhat_lower`, `yhat_upper`).\n",
    "4.  **Filter for Q2:** The resulting forecast DataFrame is then filtered to isolate the predictions specifically for Q2 2025 (April 1 to June 30).\n",
    "5.  **Display Results:** The daily predicted sales for Q2 2025 are displayed. The total predicted sales for the quarter are also calculated and printed.\n",
    "6.  **Visualization:** A plot is generated showing the historical data (from `train_df`), the full forecast period generated (if it extends beyond Q2), and specifically highlights the Q2 2025 forecast period with vertical lines.\n",
    "\n",
    "**Interpreting the Output:**\n",
    "\n",
    "*   The output table shows daily predictions (`yhat`) for Q2 2025.\n",
    "*   `trend` indicates the baseline sales predicted by the Gradient Boosting model.\n",
    "*   `residual` shows the adjustment made by the LSTM model to the GB trend.\n",
    "*   `yhat_lower` and `yhat_upper` provide a 95% confidence interval for the predictions.\n",
    "*   The total predicted sales for Q2 gives an aggregate forecast for the quarter.\n",
    "*   The plot helps visualize the Q2 forecast in the context of historical trends and model behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gb_lstm_model' in locals() and gb_lstm_model.gb_model is not None and hasattr(gb_lstm_model, 'last_date') and gb_lstm_model.last_date is not None:\n",
    "    print(\"--- Predicting Sales for Q2 2025 (April, May, June) ---\")\n",
    "    \n",
    "    model_last_training_date = gb_lstm_model.last_date\n",
    "    q2_start_date = pd.to_datetime('2025-04-01')\n",
    "    q2_end_date = pd.to_datetime('2025-06-30')\n",
    "    \n",
    "    if model_last_training_date >= q2_end_date:\n",
    "        print(f\"Q2 2025 (up to {q2_end_date.strftime('%Y-%m-%d')}) is within or before the model's last training date ({model_last_training_date.strftime('%Y-%m-%d')}).\")\n",
    "        print(\"Forecasting for this period might reflect training/validation data rather than true future predictions if Q2 overlaps with validation.\")\n",
    "        # If Q2 is entirely within training data, direct lookup might be more appropriate than prediction.\n",
    "        # However, we will proceed to generate predictions using the model's state at end of training.\n",
    "        # Number of periods will be from Q2 start to Q2 end for this specific case.\n",
    "        # Ensure make_future_dataframe can handle a start date for periods if it's not just extending from last_date.\n",
    "        # For simplicity, we'll use the standard make_future_dataframe from last_date and then filter.\n",
    "        # This means if last_date is, e.g., 2025-03-15, and Q2 starts 2025-04-01, we predict from 2025-03-16.\n",
    "        if model_last_training_date < q2_start_date: # If Q2 is entirely in the future of training data\n",
    "            num_periods_needed = (q2_end_date - model_last_training_date).days\n",
    "        else: # If Q2 starts before or on the last training date (e.g. overlap with validation)\n",
    "             # We still want to see predictions for Q2, so forecast enough to cover it.\n",
    "            num_periods_needed = (q2_end_date - model_last_training_date).days\n",
    "            if num_periods_needed <=0: # if q2_end_date is before or same as last_date\n",
    "                 print(\"Q2 end date is not after the model's last training date. Cannot make 'future' predictions for Q2 in this manner.\")\n",
    "                 num_periods_needed = 0 # Avoids error in make_future_dataframe\n",
    "\n",
    "    else: # Q2 is purely in the future\n",
    "        num_periods_needed = (q2_end_date - model_last_training_date).days\n",
    "    \n",
    "    if num_periods_needed > 0:\n",
    "        print(f\"Model's last training date: {model_last_training_date.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Forecasting {num_periods_needed} periods to reach {q2_end_date.strftime('%Y-%m-%d')}.\")\n",
    "        \n",
    "        # Generate a DataFrame for the entire period from last training date up to Q2 end.\n",
    "        # make_future_dataframe creates dates from self.last_date + 1 day onwards.\n",
    "        all_future_dates_df = gb_lstm_model.make_future_dataframe(periods=num_periods_needed)\n",
    "        \n",
    "        if not all_future_dates_df.empty:\n",
    "            print(f\"Shape of future dates df created by make_future_dataframe: {all_future_dates_df.shape}\")\n",
    "            print(f\"First few rows of future dates df:\\n{all_future_dates_df.head()}\")\n",
    "            # Perform prediction on this entire range\n",
    "            all_future_forecasts_df = gb_lstm_model.predict(future_df=all_future_dates_df)\n",
    "            \n",
    "            # Filter for Q2 2025 dates\n",
    "            all_future_forecasts_df['ds'] = pd.to_datetime(all_future_forecasts_df['ds'])\n",
    "            q2_2025_mask = (all_future_forecasts_df['ds'] >= q2_start_date) & (all_future_forecasts_df['ds'] <= q2_end_date)\n",
    "            q2_2025_forecast_df = all_future_forecasts_df[q2_2025_mask]\n",
    "            \n",
    "            if not q2_2025_forecast_df.empty:\n",
    "                print(\"\\nDaily Predicted Sales for Q2 2025 (April-June):\")\n",
    "                display(q2_2025_forecast_df[['ds', 'yhat', 'trend', 'residual', 'yhat_lower', 'yhat_upper']].style.format({'yhat': '{:.2f}', 'trend': '{:.2f}', 'residual': '{:.2f}', 'yhat_lower': '{:.2f}', 'yhat_upper': '{:.2f}'}))\n",
    "                \n",
    "                total_q2_predicted_sales = q2_2025_forecast_df['yhat'].sum()\n",
    "                print(f\"\\nTotal Predicted Sales for Q2 2025: {total_q2_predicted_sales:.2f}\")\n",
    "                \n",
    "                # Visualization\n",
    "                print(\"\\nPlotting Q2 2025 Forecast with Historical Context...\")\n",
    "                # Use train_df for historical context in the plot\n",
    "                # The `all_future_forecasts_df` contains the forecast from the day after training up to Q2 end.\n",
    "                fig_q2 = gb_lstm_model.plot_forecast(\n",
    "                    forecast_df=all_future_forecasts_df, \n",
    "                    historical_df=train_df, # train_df has 'Date' and 'Sales' columns\n",
    "                    date_col='Date', \n",
    "                    target_col='Sales',\n",
    "                    highlight_date=None # No specific single date to highlight, Q2 period is marked by axvline\n",
    "                )\n",
    "                plt.title(f'Sales Forecast: Training Data up to {model_last_training_date.strftime(\"%Y-%m-%d\")} and Future Predictions including Q2 2025')\n",
    "                plt.axvline(q2_start_date, color='orange', linestyle='--', label='Q2 2025 Start')\n",
    "                plt.axvline(q2_end_date, color='orange', linestyle='--', label='Q2 2025 End')\n",
    "                \n",
    "                # Adjust x-axis limits to provide better context around Q2\n",
    "                plot_start_date = train_df['Date'].min() # Start from beginning of training data\n",
    "                if not q2_2025_forecast_df.empty:\n",
    "                    plot_end_date = q2_end_date + pd.Timedelta(days=30) # Extend a bit beyond Q2\n",
    "                    plt.xlim([plot_start_date, plot_end_date])\n",
    "                \n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"No predictions generated for the Q2 2025 date range after filtering.\")\n",
    "        else:\n",
    "            print(\"make_future_dataframe did not return any dates. Cannot proceed with Q2 forecast.\")\n",
    "    elif num_periods_needed == 0:\n",
    "        # This case is handled by the earlier print about Q2 end date not being after last training date.\n",
    "        pass # No action needed, message already printed\n",
    "    else: # num_periods_needed < 0\n",
    "        print(f\"Error: Q2 2025 end date ({q2_end_date.strftime('%Y-%m-%d')}) is before the model's last training date ({model_last_training_date.strftime('%Y-%m-%d')}). Cannot forecast for Q2.\")\n",
    "else:\n",
    "    print(\"Model (gb_lstm_model) or its required attributes (like last_date) not found or not trained. Skipping Q2 2025 prediction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This cell now contains the month_dropdown
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b990d81a2423489d4e760e7de2ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Month:', options=('2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06', '202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months_2025 = [f'2025-{str(m).zfill(2)}' for m in range(1, 13)]\n",
    "month_dropdown = widgets.Dropdown(options=months_2025, description='Month:')\n",
    "display(month_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This cell has the GB+LSTM model definition
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sales for 2025-06: 472.77\n",
      "472.7653629314859\n"
     ]
    }
   ],
   "source": [
    "# def predict_sales(selected_month):\n",
    "#     month_num = (pd.to_datetime(selected_month).year - df['Date'].dt.year.min()) * 12 + pd.to_datetime(selected_month).month\n",
    "#     pred = model.predict(np.array([[month_num]]))[0]\n",
    "#     print(f'Predicted sales for {selected_month}: {pred:.2f}')\n",
    "#     return pred\n",
    "#     predict_button = widgets.Button(description='Predict Sales')\n",
    "# def on_predict_clicked(b):\n",
    "#     predict_sales(month_dropdown.value)\n",
    "#     predict_button.on_click(on_predict_clicked)\n",
    "#     display(predict_button)\n",
    "# print(predict_sales(month_dropdown.value))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EnhancedHybridModel:\n",
    "    \"\"\"\n",
    "    Enhanced Hybrid Time Series Model combining Gradient Boosting and LSTM\n",
    "    with clear prediction display functionality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback=12, lstm_units=64, dropout_rate=0.2,\n",
    "                 n_estimators=100, learning_rate=0.1,\n",
    "                 epochs=100, batch_size=32):\n",
    "        # Model parameters\n",
    "        self.lookback = lookback\n",
    "        self.lstm_units = lstm_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialize models and scalers\n",
    "        self.lstm_model = None\n",
    "        self.gb_model = None # This will be GradientBoostingRegressor\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        \n",
    "        # Track data properties\n",
    "        self.last_date = None\n",
    "        self.freq = None\n",
    "        self.last_sequence = None\n",
    "        # Define the feature columns that the GB model will use\n",
    "        self.gb_feature_columns = ['Month', 'Year', 'DayOfWeek', 'Quarter', 'DayOfYear', 'WeekOfYear']\n",
    "        \n",
    "    # _create_time_features is removed as we now expect features to be pre-calculated \n",
    "    # or calculated in make_future_dataframe and fit method directly from input df.\n",
    "\n",
    "    def _create_sequences(self, data):\n",
    "        \"\"\"Create sequence data for LSTM\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.lookback):\n",
    "            X.append(data[i:(i + self.lookback), 0])\n",
    "            y.append(data[i + self.lookback, 0])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def _build_lstm_model(self, input_shape):\n",
    "        \"\"\"Build LSTM model architecture\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=self.lstm_units, return_sequences=True, \n",
    "                       input_shape=input_shape))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(LSTM(units=self.lstm_units//2))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "    \n",
    "    def fit(self, df_train, date_col='Date', target_col='Sales', validation_df_gb=None, verbose=1):\n",
    "        \"\"\"\n",
    "        Fit both models to the training data, with optional GB validation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df_train : pandas.DataFrame\n",
    "            Training DataFrame. 'Date' must be a column.\n",
    "        date_col : str\n",
    "            Name of the date column\n",
    "        target_col : str\n",
    "            Name of the target column\n",
    "        verbose : int\n",
    "            Verbosity level (0=silent, 1=progress, 2=detailed)\n",
    "        \"\"\"\n",
    "        if verbose > 0:\n",
    "            print(\"Preparing data for hybrid model training...\")\n",
    "        \n",
    "        # Ensure date_col is datetime for training data\n",
    "        df_train[date_col] = pd.to_datetime(df_train[date_col])\n",
    "\n",
    "        # Store properties for forecasting using training data\n",
    "        self.last_date = df_train[date_col].max()\n",
    "        self.freq = pd.infer_freq(df_train[date_col])\n",
    "        if self.freq is None:\n",
    "            if len(df_train[date_col]) >= 2:\n",
    "                self.freq = pd.infer_freq(df_train[date_col].sort_values())\n",
    "            if self.freq is None:\n",
    "                self.freq = 'D'\n",
    "                if verbose > 0:\n",
    "                    print(f\"Could not infer frequency from training data, defaulting to '{self.freq}'.\")\n",
    "        \n",
    "        # Select pre-defined feature columns for GB model from training data\n",
    "        # Ensure these columns are present in df_train\n",
    "        missing_cols = [col for col in self.gb_feature_columns if col not in df_train.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required feature columns in training data: {missing_cols}\")\n",
    "        train_gb_features = df_train[self.gb_feature_columns]\n",
    "        \n",
    "        # Train GB model on these features\n",
    "        if verbose > 0:\n",
    "            print(f\"Training Gradient Boosting model on features: {self.gb_feature_columns} with shape {train_gb_features.shape}...\")\n",
    "            \n",
    "        self.gb_model = GradientBoostingRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_depth=5, # Example, can be tuned\n",
    "            random_state=42\n",
    "        )\n",
    "        self.gb_model.fit(train_gb_features, df_train[target_col])\n",
    "        \n",
    "        # Optional: Evaluate GB model on validation set (if provided and has features)\n",
    "        if validation_df_gb is not None and not validation_df_gb.empty:\n",
    "            # Ensure validation_df_gb also has the required feature columns\n",
    "            val_missing_cols = [col for col in self.gb_feature_columns if col not in validation_df_gb.columns]\n",
    "            if not val_missing_cols:\n",
    "                if verbose > 0:\n",
    "                    print(f\"Evaluating GB model on validation data with features: {self.gb_feature_columns}...\")\n",
    "                validation_gb_features = validation_df_gb[self.gb_feature_columns]\n",
    "                gb_val_predictions = self.gb_model.predict(validation_gb_features)\n",
    "                r2 = r2_score(validation_df_gb[target_col], gb_val_predictions)\n",
    "                if verbose > 0:\n",
    "                    print(f\"Gradient Boosting model R-squared on validation data: {r2:.4f}\")\n",
    "            else:\n",
    "                if verbose > 0:\n",
    "                    print(f\"Warning: Validation data for GB model is missing columns: {val_missing_cols}. Skipping GB validation.\")\n",
    "\n",
    "        # Get GB predictions on training data to calculate residuals for LSTM\n",
    "        gb_train_predictions = self.gb_model.predict(train_gb_features).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate residuals from training data for LSTM\n",
    "        train_residuals = df_train[target_col].values.reshape(-1, 1) - gb_train_predictions\n",
    "        scaled_train_residuals = self.scaler.fit_transform(train_residuals)\n",
    "        \n",
    "        # Create sequences for LSTM from training residuals\n",
    "        X_lstm_train, y_lstm_train = self._create_sequences(scaled_train_residuals)\n",
    "        if len(X_lstm_train) == 0:\n",
    "            raise ValueError(f\"Not enough data in training set to create LSTM sequences with lookback {self.lookback}. Need at least {self.lookback + 1} data points in training set.\")\n",
    "        X_lstm_train = X_lstm_train.reshape(X_lstm_train.shape[0], X_lstm_train.shape[1], 1)\n",
    "        \n",
    "        # Store last sequence from training residuals for forecasting\n",
    "        self.last_sequence = scaled_train_residuals[-self.lookback:].reshape(1, self.lookback, 1)\n",
    "        \n",
    "        # Train LSTM model on training residuals\n",
    "        if verbose > 0:\n",
    "            print(f\"Training LSTM model on residuals of shape {X_lstm_train.shape}...\")\n",
    "            \n",
    "        self.lstm_model = self._build_lstm_model((X_lstm_train.shape[1], 1))\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            # ModelCheckpoint('hybrid_model_gb_lstm.h5', save_best_only=True) # Optional: save model\n",
    "        ]\n",
    "        \n",
    "        self.lstm_model.fit(\n",
    "            X_lstm_train, y_lstm_train,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=0.2, # Keras internal validation split on the training residuals\n",
    "            verbose=(1 if verbose > 1 else 0),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(\"EnhancedHybridModel (GB+LSTM) training complete!\")\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def make_future_dataframe(self, periods):\n",
    "        \"\"\"\n",
    "        Create a dataframe of future dates for forecasting\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        periods : int\n",
    "            Number of periods to forecast\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        future_df : pandas.DataFrame\n",
    "            DataFrame with future dates\n",
    "        \"\"\"\n",
    "        if self.last_date is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "            \n",
    "        future_dates = pd.date_range(\n",
    "            start=self.last_date + pd.Timedelta(days=1 if self.freq == 'D' else 1), # Adjust based on freq for daily data\n",
    "            periods=periods,\n",
    "            freq=self.freq\n",
    "        )\n",
    "        future_df_with_dates = pd.DataFrame({'ds': future_dates})\n",
    "        \n",
    "        # Add the required features to this future_df\n",
    "        # These should match self.gb_feature_columns\n",
    "        future_df_with_dates['Date'] = pd.to_datetime(future_df_with_dates['ds'])\n",
    "        future_df_with_dates.set_index('Date', inplace=True) # Temporarily set index to use .dt accessor style\n",
    "        \n",
    "        future_df_with_dates['Month'] = future_df_with_dates.index.month\n",
    "        future_df_with_dates['Year'] = future_df_with_dates.index.year\n",
    "        future_df_with_dates['DayOfWeek'] = future_df_with_dates.index.dayofweek\n",
    "        future_df_with_dates['Quarter'] = future_df_with_dates.index.quarter\n",
    "        future_df_with_dates['DayOfYear'] = future_df_with_dates.index.dayofyear\n",
    "        future_df_with_dates['WeekOfYear'] = future_df_with_dates.index.isocalendar().week.astype(int)\n",
    "        \n",
    "        future_df_with_dates.reset_index(drop=True, inplace=True) # Remove 'Date' index, keep 'ds'\n",
    "        # future_df_with_dates = future_df_with_dates.drop(columns=['Date']) # Drop the extra 'Date' column if it was created\n",
    "        return future_df_with_dates\n",
    "    \n",
    "    def predict(self, future_df=None, periods=None):\n",
    "        \"\"\"\n",
    "        Generate predictions with the hybrid model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        future_df : pandas.DataFrame\n",
    "            DataFrame with future dates ('ds' column)\n",
    "        periods : int\n",
    "            Number of periods to forecast (used if future_df not provided)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        forecast_df : pandas.DataFrame\n",
    "            DataFrame with predictions\n",
    "        \"\"\"\n",
    "        if self.lstm_model is None or self.gb_model is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "            \n",
    "        if future_df is None and periods is not None:\n",
    "            future_df = self.make_future_dataframe(periods)\n",
    "        elif future_df is None and periods is None:\n",
    "            raise ValueError(\"Either future_df or periods must be provided\")\n",
    "        \n",
    "        # Ensure future_df has the required feature columns\n",
    "        missing_future_cols = [col for col in self.gb_feature_columns if col not in future_df.columns]\n",
    "        if missing_future_cols:\n",
    "            # This might happen if make_future_dataframe was not used or did not create all features\n",
    "            raise ValueError(f\"Missing required feature columns in future_df for prediction: {missing_future_cols}. Ensure make_future_dataframe populates these.\")\n",
    "            \n",
    "        # Get GB predictions for trend/seasonality using pre-defined features\n",
    "        future_gb_features = future_df[self.gb_feature_columns]\n",
    "        gb_predictions = self.gb_model.predict(future_gb_features).reshape(-1, 1)\n",
    "        \n",
    "        # Generate LSTM predictions for residuals\n",
    "        lstm_forecasts = []\n",
    "        current_sequence = self.last_sequence.copy()\n",
    "        \n",
    "        for _ in range(len(future_df)):\n",
    "            # Predict next residual\n",
    "            next_pred = self.lstm_model.predict(current_sequence, verbose=0)\n",
    "            lstm_forecasts.append(next_pred[0, 0])\n",
    "            \n",
    "            # Update sequence for next prediction\n",
    "            current_sequence = np.append(current_sequence[:, 1:, :], \n",
    "                                        [[next_pred[0, 0]]], \n",
    "                                        axis=1)\n",
    "        \n",
    "        # Convert to array and inverse transform\n",
    "        lstm_forecasts = np.array(lstm_forecasts).reshape(-1, 1)\n",
    "        lstm_forecasts = self.scaler.inverse_transform(lstm_forecasts)\n",
    "        \n",
    "        # Combine predictions\n",
    "        final_forecasts = gb_predictions + lstm_forecasts\n",
    "        \n",
    "        # Create forecast dataframe\n",
    "        forecast_df = future_df.copy()\n",
    "        forecast_df['yhat'] = final_forecasts\n",
    "        forecast_df['trend'] = gb_predictions\n",
    "        forecast_df['residual'] = lstm_forecasts\n",
    "        \n",
    "        # Add confidence intervals (simplified - based on overall std of residuals)\n",
    "        # A more robust CI would consider variance from both GB and LSTM models\n",
    "        # The current self.last_sequence is from training residuals, so this std might be an approximation.\n",
    "        if self.last_sequence is not None and len(self.last_sequence) > 0:\n",
    "             # Predict on the last known sequence to estimate residual std dev for CI\n",
    "            lstm_pred_on_last_seq = self.lstm_model.predict(self.last_sequence, verbose=0)\n",
    "            unscaled_lstm_pred_on_last_seq = self.scaler.inverse_transform(lstm_pred_on_last_seq)\n",
    "            residual_std_dev = np.std(unscaled_lstm_pred_on_last_seq) \n",
    "        else: # Fallback if last_sequence is problematic\n",
    "            residual_std_dev = np.std(lstm_forecasts) # Use std of current batch of forecasts\n",
    "            \n",
    "        forecast_df['yhat_lower'] = forecast_df['yhat'] - 1.96 * residual_std_dev\n",
    "        forecast_df['yhat_upper'] = forecast_df['yhat'] + 1.96 * residual_std_dev\n",
    "        \n",
    "        return forecast_df\n",
    "    \n",
    "    def display_prediction_for_month(self, forecast_df, target_date):\n",
    "        \"\"\"\n",
    "        Display the prediction for a specific month clearly\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        forecast_df : pandas.DataFrame\n",
    "            DataFrame with forecasts from predict()\n",
    "        target_date : str or datetime\n",
    "            The date to find predictions for\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        prediction_info : dict\n",
    "            Dictionary with prediction details\n",
    "        \"\"\"\n",
    "        # Convert target_date to datetime if it's a string\n",
    "        if isinstance(target_date, str):\n",
    "            target_date = pd.to_datetime(target_date)\n",
    "            \n",
    "        # Find the forecast for the target date (ensure 'ds' is datetime)\n",
    "        forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "        selected_forecast = forecast_df[forecast_df['ds'].dt.strftime('%Y-%m-%d') == target_date.strftime('%Y-%m-%d')]\n",
    "        \n",
    "        if selected_forecast.empty:\n",
    "            print(f\"⚠️ No forecast available for {target_date.strftime('%Y-%m-%d')}. Ensure the date is within the forecast range and format matches.\")\n",
    "            return None\n",
    "        \n",
    "        # Get prediction values\n",
    "        predicted_value = selected_forecast['yhat'].values[0]\n",
    "        trend_component = selected_forecast['trend'].values[0]\n",
    "        residual_component = selected_forecast['residual'].values[0]\n",
    "        lower_bound = selected_forecast['yhat_lower'].values[0]\n",
    "        upper_bound = selected_forecast['yhat_upper'].values[0]\n",
    "        \n",
    "        # Display prediction\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"📊 FORECAST FOR {target_date.strftime('%B %d, %Y').upper()}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"📈 Predicted Sales: {predicted_value:.2f}\")\n",
    "        print(f\"⚖️ Confidence Interval: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(\"\\nComponent Breakdown:\")\n",
    "        print(f\"🔹 Trend/Seasonal (GB): {trend_component:.2f} ({(trend_component/predicted_value*100 if predicted_value else 0):.1f}%)\")\n",
    "        print(f\"🔹 Residual (LSTM): {residual_component:.2f} ({(residual_component/predicted_value*100 if predicted_value else 0):.1f}%)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Return prediction info as dictionary\n",
    "        return {\n",
    "            'date': target_date,\n",
    "            'prediction': predicted_value,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'trend': trend_component,\n",
    "            'residual': residual_component\n",
    "        }\n",
    "    \n",
    "    def plot_forecast(self, forecast_df, historical_df=None, \n",
    "                     date_col='Date', target_col='Sales',\n",
    "                     highlight_date=None):\n",
    "        \"\"\"\n",
    "        Plot the forecast with optional historical data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        forecast_df : pandas.DataFrame\n",
    "            DataFrame with forecasts ('ds', 'yhat', 'yhat_lower', 'yhat_upper')\n",
    "        historical_df : pandas.DataFrame\n",
    "            DataFrame with historical data (must have date_col and target_col)\n",
    "        date_col : str\n",
    "            Name of date column in historical data\n",
    "        target_col : str\n",
    "            Name of target column in historical data\n",
    "        highlight_date : datetime\n",
    "            Specific date to highlight in the forecast\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        \n",
    "        # Plot historical data if provided\n",
    "        if historical_df is not None:\n",
    "            plt.plot(pd.to_datetime(historical_df[date_col]), historical_df[target_col],\n",
    "                    color='#3366CC', linewidth=2, label='Historical Data')\n",
    "            \n",
    "            # Add vertical line separating historical and forecast\n",
    "            last_historical_date = pd.to_datetime(historical_df[date_col]).max()\n",
    "            plt.axvline(x=last_historical_date, color='gray', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Plot forecast\n",
    "        plt.plot(pd.to_datetime(forecast_df['ds']), forecast_df['yhat'],\n",
    "                color='#E74C3C', linewidth=2, label='Forecast')\n",
    "        \n",
    "        # Plot confidence interval\n",
    "        plt.fill_between(pd.to_datetime(forecast_df['ds']),\n",
    "                        forecast_df['yhat_lower'],\n",
    "                        forecast_df['yhat_upper'],\n",
    "                        alpha=0.2, color='#E74C3C', label='95% Confidence Interval')\n",
    "        \n",
    "        # Highlight specific date if provided\n",
    "        if highlight_date is not None:\n",
    "            highlight_date = pd.to_datetime(highlight_date)\n",
    "            highlight_forecast = forecast_df[pd.to_datetime(forecast_df['ds']).dt.strftime('%Y-%m-%d') == highlight_date.strftime('%Y-%m-%d')]\n",
    "            if not highlight_forecast.empty:\n",
    "                plt.scatter(highlight_date, highlight_forecast['yhat'].values[0],\n",
    "                          color='green', s=100, zorder=5, label=f'Forecast for {highlight_date.strftime(\"%b %d, %Y\")}')\n",
    "        \n",
    "        # Add title and labels\n",
    "        plt.title('Hybrid Model Forecast (GB + LSTM)', fontsize=16)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Sales', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt\n",
    "\n",
    "# The commented out section below is an example of how to use the model.\n",
    "# It has been moved to the cell where the model is actually trained and used.\n",
    "\"\"\"\n",
    "# # Prepare data\n",
    "# df_daily_sales_reset = df_daily_sales.reset_index() # Ensure 'Date' is a column\n",
    "# \n",
    "# # Initialize and train the hybrid model\n",
    "# model = EnhancedHybridModel(\n",
    "#     lookback=12,\n",
    "#     lstm_units=64,\n",
    "#     dropout_rate=0.2,\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.05,\n",
    "#     epochs=50\n",
    "# )\n",
    "# model.fit(df_daily_sales_reset, date_col='Date', target_col='Sales')\n",
    "# \n",
    "# # Get selected month from dropdown\n",
    "# future_date = pd.to_datetime(month_dropdown.value)\n",
    "# \n",
    "# # Create future dataframe and generate forecast\n",
    "# future = model.make_future_dataframe(periods=36)\n",
    "# forecast = model.predict(future)\n",
    "# \n",
    "# # Display prediction for selected month\n",
    "# prediction_info = model.display_prediction_for_month(forecast, future_date)\n",
    "# \n",
    "# # Visualize the forecast\n",
    "# model.plot_forecast(forecast, historical_df=df_daily_sales_reset, date_col='Date', target_col='Sales', highlight_date=future_date)\n",
    "# plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This was old plot_prediction function
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell used to define and call a plot_prediction function for the old LinearRegression model.\n",
    "# It is now fully commented out as the EnhancedHybridModel has its own plotting capabilities.\n",
    "# def plot_prediction(selected_month):\n",
    "#    month_num = (pd.to_datetime(selected_month).year - df['Date'].dt.year.min()) * 12 + pd.to_datetime(selected_month).month\n",
    "#    future_X = np.append(X, [[month_num]], axis=0)\n",
    "#    future_y = np.append(y, [model.predict(np.array([[month_num]]))[0]])\n",
    "#    plt.figure(figsize=(10,5))\n",
    "#    plt.plot(df['Date'], y, label='Historical Sales', marker='o')\n",
    "#    plt.scatter([pd.to_datetime(selected_month)], [future_y[-1]], color='red', label='Predicted')\n",
    "#    plt.xlabel('Date')\n",
    "#    plt.ylabel('Sales')\n",
    "#    plt.title('Sales Prediction')\n",
    "#    plt.legend()\n",
    "#    plt.show()\n",
    "# print(plot_prediction(month_dropdown.value))\n",
    "print(\"Old plot_prediction function cell - now commented out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null, # This cell was the RandomForest model, now commented.
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell previously defined an EnhancedHybridModel using RandomForestRegressor.\n",
    "# It is now fully commented out to ensure only the GradientBoostingRegressor version is used.\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# class EnhancedHybridModel:\n",
    "#     \"\"\"\n",
    "#     Enhanced Hybrid Time Series Model combining Random Forest and LSTM\n",
    "#     with clear prediction display functionality.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, lookback=12, lstm_units=64, dropout_rate=0.2,\n",
    "#                  n_estimators=100, epochs=100, batch_size=32):\n",
    "#         self.lookback = lookback\n",
    "#         self.lstm_units = lstm_units\n",
    "#         self.dropout_rate = dropout_rate\n",
    "#         self.n_estimators = n_estimators\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.lstm_model = None\n",
    "#         self.gb_model = None # This would be RandomForest\n",
    "#         self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#         self.last_date = None\n",
    "#         self.freq = None\n",
    "#         self.last_sequence = None\n",
    "#\n",
    "#     def _create_time_features(self, dates):\n",
    "#         if not isinstance(dates, pd.DatetimeIndex):\n",
    "#             dates = pd.DatetimeIndex(dates)\n",
    "#         features = pd.DataFrame({\n",
    "#             'year': dates.year,\n",
    "#             'month': dates.month,\n",
    "#             'quarter': dates.quarter,\n",
    "#             'dayofyear': dates.dayofyear,\n",
    "#             'weekofyear': dates.isocalendar().week.astype(int),\n",
    "#             'is_month_start': dates.is_month_start.astype(int),\n",
    "#             'is_month_end': dates.is_month_end.astype(int),\n",
    "#             'is_quarter_start': dates.is_quarter_start.astype(int),\n",
    "#             'is_quarter_end': dates.is_quarter_end.astype(int),\n",
    "#             'is_year_start': dates.is_year_start.astype(int),\n",
    "#             'is_year_end': dates.is_year_end.astype(int)\n",
    "#         })\n",
    "#         for col in ['month', 'quarter']:\n",
    "#             max_val = 12 if col == 'month' else 4\n",
    "#             features[f'{col}_sin'] = np.sin(2 * np.pi * features[col] / max_val)\n",
    "#             features[f'{col}_cos'] = np.cos(2 * np.pi * features[col] / max_val)\n",
    "#         return features\n",
    "#\n",
    "#     def _create_sequences(self, data):\n",
    "#         X, y = [], []\n",
    "#         for i in range(len(data) - self.lookback):\n",
    "#             X.append(data[i:(i + self.lookback), 0])\n",
    "#             y.append(data[i + self.lookback, 0])\n",
    "#         return np.array(X), np.array(y)\n",
    "#\n",
    "#     def _build_lstm_model(self, input_shape):\n",
    "#         model = Sequential()\n",
    "#         model.add(LSTM(units=self.lstm_units, return_sequences=True, input_shape=input_shape))\n",
    "#         model.add(Dropout(self.dropout_rate))\n",
    "#         model.add(LSTM(units=self.lstm_units//2))\n",
    "#         model.add(Dropout(self.dropout_rate))\n",
    "#         model.add(Dense(1))\n",
    "#         model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#         return model\n",
    "#\n",
    "#     def fit(self, df, date_col='Date', target_col='Sales', verbose=1):\n",
    "#         if verbose > 0:\n",
    "#             print(\"Preparing data for Random Forest hybrid model training...\")\n",
    "#         df[date_col] = pd.to_datetime(df[date_col])\n",
    "#         self.last_date = df[date_col].max()\n",
    "#         self.freq = pd.infer_freq(df[date_col])\n",
    "#         if self.freq is None: self.freq = 'D'\n",
    "#         time_features = self._create_time_features(df[date_col])\n",
    "#         if verbose > 0:\n",
    "#             print(\"Training Random Forest model...\")\n",
    "#         self.gb_model = RandomForestRegressor(\n",
    "#             n_estimators=self.n_estimators,\n",
    "#             max_depth=5, # Example, tune this\n",
    "#             random_state=42\n",
    "#         )\n",
    "#         self.gb_model.fit(time_features, df[target_col])\n",
    "#         gb_predictions = self.gb_model.predict(time_features).reshape(-1, 1)\n",
    "#         residuals = df[target_col].values.reshape(-1, 1) - gb_predictions\n",
    "#         scaled_residuals = self.scaler.fit_transform(residuals)\n",
    "#         X_lstm, y_lstm = self._create_sequences(scaled_residuals)\n",
    "#         if len(X_lstm) == 0: raise ValueError(\"Not enough data for LSTM sequences.\")\n",
    "#         X_lstm = X_lstm.reshape(X_lstm.shape[0], X_lstm.shape[1], 1)\n",
    "#         self.last_sequence = scaled_residuals[-self.lookback:].reshape(1, self.lookback, 1)\n",
    "#         if verbose > 0: print(\"Training LSTM model on residuals...\")\n",
    "#         self.lstm_model = self._build_lstm_model((X_lstm.shape[1], 1))\n",
    "#         callbacks = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "#         self.lstm_model.fit(X_lstm, y_lstm, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2, verbose=0, callbacks=callbacks)\n",
    "#         if verbose > 0: print(\"Random Forest Hybrid Model training complete!\")\n",
    "#         return self\n",
    "#\n",
    "#     def make_future_dataframe(self, periods):\n",
    "#         if self.last_date is None: raise ValueError(\"Model not fitted.\")\n",
    "#         future_dates = pd.date_range(start=self.last_date + pd.Timedelta(days=1), periods=periods, freq=self.freq)\n",
    "#         return pd.DataFrame({'ds': future_dates})\n",
    "#\n",
    "#     def predict(self, future_df=None, periods=None):\n",
    "#         if self.lstm_model is None or self.gb_model is None: raise ValueError(\"Model not fitted.\")\n",
    "#         if future_df is None and periods is not None: future_df = self.make_future_dataframe(periods)\n",
    "#         elif future_df is None and periods is None: raise ValueError(\"Provide future_df or periods.\")\n",
    "#         future_features = self._create_time_features(future_df['ds'])\n",
    "#         gb_predictions = self.gb_model.predict(future_features).reshape(-1, 1)\n",
    "#         lstm_forecasts = []\n",
    "#         current_sequence = self.last_sequence.copy()\n",
    "#         for _ in range(len(future_df)):\n",
    "#             next_pred = self.lstm_model.predict(current_sequence, verbose=0)\n",
    "#             lstm_forecasts.append(next_pred[0, 0])\n",
    "#             current_sequence = np.append(current_sequence[:, 1:, :], [[next_pred[0, 0]]], axis=1)\n",
    "#         lstm_forecasts = self.scaler.inverse_transform(np.array(lstm_forecasts).reshape(-1, 1))\n",
    "#         final_forecasts = gb_predictions + lstm_forecasts\n",
    "#         forecast_df = future_df.copy()\n",
    "#         forecast_df['yhat'] = final_forecasts\n",
    "#         forecast_df['trend'] = gb_predictions\n",
    "#         forecast_df['residual'] = lstm_forecasts\n",
    "#         # Simplified CI\n",
    "#         residual_std_dev = np.std(self.scaler.inverse_transform(self.lstm_model.predict(self.last_sequence, verbose=0)))\n",
    "#         forecast_df['yhat_lower'] = forecast_df['yhat'] - 1.96 * residual_std_dev\n",
    "#         forecast_df['yhat_upper'] = forecast_df['yhat'] + 1.96 * residual_std_dev\n",
    "#         return forecast_df\n",
    "#\n",
    "#     def display_prediction_for_month(self, forecast_df, target_date):\n",
    "#         # Similar to GB version, adjust title if needed\n",
    "#         if isinstance(target_date, str): target_date = pd.to_datetime(target_date)\n",
    "#         forecast_df['ds'] = pd.to_datetime(forecast_df['ds'])\n",
    "#         selected_forecast = forecast_df[forecast_df['ds'].dt.strftime('%Y-%m-%d') == target_date.strftime('%Y-%m-%d')]\n",
    "#         if selected_forecast.empty: print(f\"No forecast for {target_date.strftime('%Y-%m-%d')}.\"); return None\n",
    "#         # ... (rest of display logic similar to GB version, ensure component names are RF)\n",
    "#         print(f\"Trend/Seasonal (RF): {selected_forecast['trend'].values[0]:.2f}\") # Example adjustment\n",
    "#         return selected_forecast.iloc[0].to_dict()\n",
    "#\n",
    "#     def plot_forecast(self, forecast_df, historical_df=None, date_col='Date', target_col='Sales', highlight_date=None):\n",
    "#         # Similar to GB version, adjust title if needed\n",
    "#         plt.title('Hybrid Model Forecast (Random Forest + LSTM)', fontsize=16)\n",
    "#         # ... (rest of plotting logic similar to GB version)\n",
    "#         return plt\n",
    "#\n",
    "print(\"Old RandomForest Hybrid Model cell - now commented out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
